{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9LAJHmSmF84"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW4fMCshWBrD",
        "outputId": "25b9653d-da21-4adf-e8b4-253b69071a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for et_util (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install osfclient --quiet\n",
        "!pip install git+https://github.com/jspsych/eyetracking-utils.git --quiet\n",
        "!pip install keras_cv --quiet\n",
        "!pip install plotnine --quiet\n",
        "!pip install wandb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQRQZ3D5Vwqc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import tensorflow.keras as keras\n",
        "import keras_cv\n",
        "from plotnine import ggplot, geom_point, aes, geom_line, scale_y_reverse, theme_void, scale_color_manual\n",
        "import pandas as pd\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbMetricsLogger\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "import et_util.dataset_utils as dataset_utils\n",
        "import et_util.embedding_preprocessing as embed_pre\n",
        "import et_util.model_layers as model_layers\n",
        "from et_util import experiment_utils\n",
        "from et_util.custom_loss import normalized_weighted_euc_dist\n",
        "from et_util.model_analysis import plot_model_performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BUzHdPEc-ef"
      },
      "outputs": [],
      "source": [
        "os.environ['WANDB_API_KEY'] = userdata.get('WANDB_API_KEY')\n",
        "os.environ['OSF_TOKEN'] = userdata.get('osftoken')\n",
        "os.environ['OSF_USERNAME'] = userdata.get('osfusername')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZEsXfla-cg8G",
        "outputId": "f729c460-9188-4564-8af0-83657d689f7d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Cvv9AY4YAA43Lb17ua0cbUr0G4OAv5mvFmegj7RK8e3k4vJZt5H7AihU6nvJxVQdkdxeW3'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "userdata.get('osftoken')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3M9X95jV8du"
      },
      "outputs": [],
      "source": [
        "keras.mixed_precision.set_global_policy('mixed_float16')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er9v9bxBcHc0"
      },
      "source": [
        "# Configure W&B experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SPGBdleCfbe",
        "outputId": "e55f66c4-357c-4a8d-d890-40c78dbf14fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoshdeleeuw\u001b[0m (\u001b[33meye-tracking\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWWKsFf6p1HJ"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 200\n",
        "RIDGE_REGULARIZATION = 0.1\n",
        "TRAIN_EPOCHS = 30\n",
        "MIN_CAL_POINTS = 8\n",
        "MAX_CAL_POINTS = 40\n",
        "DENSE_NET_STACKWISE_NUM_REPEATS = [4,4,4]\n",
        "LEARNING_RATE = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkHFv5kHfaWR"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"embedding_dim\": EMBEDDING_DIM,\n",
        "    \"ridge_regularization\": RIDGE_REGULARIZATION,\n",
        "    \"train_epochs\": TRAIN_EPOCHS,\n",
        "    \"min_cal_points\": MIN_CAL_POINTS,\n",
        "    \"max_cal_points\": MAX_CAL_POINTS,\n",
        "    \"dense_net_stackwise_num_repeats\": DENSE_NET_STACKWISE_NUM_REPEATS,\n",
        "    \"learning_rate\": LEARNING_RATE,\n",
        "    \"augmentation\": True\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "wjDFWXNEddE9",
        "outputId": "2f834de9-b775-4784-9759-b0a28d753fa3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250314_151744-sam6als8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/eye-tracking/eye-tracking-dense-full-data-set-single-eye/runs/sam6als8' target=\"_blank\">berry-brownie-7</a></strong> to <a href='https://wandb.ai/eye-tracking/eye-tracking-dense-full-data-set-single-eye' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/eye-tracking/eye-tracking-dense-full-data-set-single-eye' target=\"_blank\">https://wandb.ai/eye-tracking/eye-tracking-dense-full-data-set-single-eye</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/eye-tracking/eye-tracking-dense-full-data-set-single-eye/runs/sam6als8' target=\"_blank\">https://wandb.ai/eye-tracking/eye-tracking-dense-full-data-set-single-eye/runs/sam6als8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    project='eye-tracking-dense-full-data-set-single-eye',\n",
        "    config=config\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKeHGiFxtvo0"
      },
      "source": [
        "# Download dataset from OSF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tswV6s38WbtO",
        "outputId": "1469acc4-f0d8-40e4-8b13-a2582ac3b005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 2.50G/2.50G [02:11<00:00, 19.0Mbytes/s]\n"
          ]
        }
      ],
      "source": [
        "!osf -p 6b5cd fetch single_eye_tfrecords.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFgWOhWTt4iD"
      },
      "source": [
        "# Process raw data records into TF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4h8QhGvWhZf"
      },
      "outputs": [],
      "source": [
        "!mkdir single_eye_tfrecords\n",
        "!tar -xf single_eye_tfrecords.tar.gz -C single_eye_tfrecords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZRcQgPadqtI"
      },
      "outputs": [],
      "source": [
        "def parse(element):\n",
        "    \"\"\"Process function that parses a tfr element in a raw dataset for process_tfr_to_tfds function.\n",
        "    Gets mediapipe landmarks, raw image, image width, image height, subject id, and xy labels.\n",
        "    Use for data generated with make_single_example_landmarks_and_jpg (i.e. data in\n",
        "    jpg_landmarks_tfrecords.tar.gz)\n",
        "\n",
        "    :param element: tfr element in raw dataset\n",
        "    :return: image, label(x,y), landmarks, subject_id\n",
        "    \"\"\"\n",
        "\n",
        "    data_structure = {\n",
        "        'landmarks': tf.io.FixedLenFeature([], tf.string),\n",
        "        'img_width': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'img_height': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'x': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'y': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'eye_img': tf.io.FixedLenFeature([], tf.string),\n",
        "        'subject_id': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "\n",
        "    content = tf.io.parse_single_example(element, data_structure)\n",
        "\n",
        "    landmarks = content['landmarks']\n",
        "    raw_image = content['eye_img']\n",
        "    width = content['img_width']\n",
        "    height = content['img_height']\n",
        "    depth = 3\n",
        "    label = [content['x'], content['y']]\n",
        "    subject_id = content['subject_id']\n",
        "\n",
        "    landmarks = tf.io.parse_tensor(landmarks, out_type=tf.float32)\n",
        "    landmarks = tf.reshape(landmarks, shape=(478, 3))\n",
        "\n",
        "    image = tf.io.parse_tensor(raw_image, out_type=tf.uint8)\n",
        "\n",
        "    return image, landmarks, label, subject_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWv57eb5XHVP"
      },
      "outputs": [],
      "source": [
        "train_data, validation_data, test_data = dataset_utils.process_tfr_to_tfds(\n",
        "    'single_eye_tfrecords/',\n",
        "    parse,\n",
        "    train_split=1.0,\n",
        "    val_split=0.0,\n",
        "    test_split=0.0,\n",
        "    random_seed=12604,\n",
        "    group_function=lambda img, landmarks, coords, z: z\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FULm58Cxu9oa"
      },
      "source": [
        "## Rescale the `x,y` coordinates to be 0-1 instead of 0-100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apcLK9klHLQV"
      },
      "outputs": [],
      "source": [
        "def rescale_coords_map(eyes, mesh, coords, id):\n",
        "  return eyes, mesh, tf.divide(coords, tf.constant([100.])), id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b47CtWKqHg0B"
      },
      "outputs": [],
      "source": [
        "train_data_rescaled = train_data.map(rescale_coords_map)\n",
        "validation_data_rescaled = validation_data.map(rescale_coords_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdQbBaKR6vLN"
      },
      "source": [
        "# Generate dataset that has calibration points, target point, and target output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCSmeKFBH5YQ"
      },
      "source": [
        "Cols = 5, 11, 17, 23, 29, 35, 41, 47, 53, 59, 65, 71, 77, 83, 89, 95\n",
        "\n",
        "Rows = 5, 16.25, 27.5, 38.75, 50, 61.25, 72.5, 83.75, 95  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP0_I2DUuEKo"
      },
      "source": [
        "Fixed Points as calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuCld98e7vAZ"
      },
      "outputs": [],
      "source": [
        "cal_points = tf.constant([\n",
        "    [5, 5],\n",
        "    [5, 27.5],\n",
        "    [5, 50],\n",
        "    [5, 72.5],\n",
        "    [5, 95],\n",
        "    [35, 5],\n",
        "    [35, 27.5],\n",
        "    [35, 50],\n",
        "    [35, 72.5],\n",
        "    [35, 95],\n",
        "    [65, 5],\n",
        "    [65, 27.5],\n",
        "    [65, 50],\n",
        "    [65, 72.5],\n",
        "    [65, 95],\n",
        "    [95, 5],\n",
        "    [95, 27.5],\n",
        "    [95, 50],\n",
        "    [95, 72.5],\n",
        "    [95, 95],\n",
        "], dtype=tf.float32)\n",
        "\n",
        "scaled_cal_points = tf.divide(cal_points, tf.constant([100.]))\n",
        "\n",
        "def filter_cal_points(image, mesh, coords, id):\n",
        "\n",
        "  return tf.reduce_any(tf.reduce_all(tf.equal(coords, scaled_cal_points), axis=1))\n",
        "\n",
        "def filter_non_cal_points(image, mesh, coords, id):\n",
        "\n",
        "  return tf.reduce_all(tf.reduce_any(tf.not_equal(coords, scaled_cal_points), axis=1))\n",
        "\n",
        "def filter_subjects_missing_cal_points(cal, target):\n",
        "\n",
        "  return tf.equal(tf.shape(cal[0])[0], tf.shape(cal_points)[0])\n",
        "\n",
        "def map_for_calibration_pts(image, mesh, coords, id):\n",
        "\n",
        "  img = tf.reshape(image, (-1, 36, 144, 1))\n",
        "\n",
        "  return img, coords\n",
        "\n",
        "def map_for_non_calibration_pts(image, mesh, coords, id):\n",
        "\n",
        "  img = tf.reshape(image, (-1, 36, 144, 1))\n",
        "\n",
        "  return img, coords\n",
        "\n",
        "def map_for_merged(cal, non_cal):\n",
        "  target_input, target_output = non_cal\n",
        "\n",
        "  return (*cal, target_input), target_output\n",
        "\n",
        "def map_for_merged_with_id(cal, non_cal, id):\n",
        "  target_input, target_output = non_cal\n",
        "\n",
        "  return (*cal, target_input), target_output, id\n",
        "\n",
        "def reducer_function(k, ds):\n",
        "\n",
        "  ds_random = ds.shuffle(144)\n",
        "\n",
        "  n_cal_points = tf.random.uniform(shape=[], minval=MIN_CAL_POINTS, maxval=MAX_CAL_POINTS, dtype=tf.int64)\n",
        "\n",
        "  calibration_points = ds_random.take(n_cal_points).batch(n_cal_points).map(map_for_calibration_pts).repeat()\n",
        "\n",
        "  non_calibration_points = ds.batch(144).map(map_for_non_calibration_pts)\n",
        "\n",
        "  merged = tf.data.Dataset.zip(calibration_points, non_calibration_points)\n",
        "  #return non_calibration_points\n",
        "  #return merged\n",
        "  return merged.map(map_for_merged)\n",
        "\n",
        "# group data by subject id, create datasets with calibration points\n",
        "def reducer_function_fixed_pts(subject_id, ds):\n",
        "\n",
        "  non_cal_points = ds.batch(144, drop_remainder=True).map(map_for_non_calibration_pts)\n",
        "\n",
        "  points = ds.filter(filter_cal_points).batch(len(cal_points), drop_remainder=True).map(map_for_calibration_pts).repeat()\n",
        "\n",
        "  merged = tf.data.Dataset.zip(points, non_cal_points)\n",
        "  #return merged\n",
        "  return merged.map(map_for_merged)\n",
        "\n",
        "def reducer_function_fixed_pts_with_id(subject_id, ds):\n",
        "\n",
        "  non_cal_points = ds.batch(144, drop_remainder=True).map(map_for_non_calibration_pts)\n",
        "\n",
        "  points = ds.filter(filter_cal_points).batch(len(cal_points)).map(map_for_calibration_pts).repeat()\n",
        "\n",
        "  merged = tf.data.Dataset.zip(points, non_cal_points)\n",
        "\n",
        "  #return merged\n",
        "  return merged.map(lambda x, y: map_for_merged_with_id(x, y, subject_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFQ-O5idYhS3"
      },
      "source": [
        "## Create augmentation pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "I9Xkt4gQYhS3"
      },
      "outputs": [],
      "source": [
        "#Create a preprocessing model\n",
        "augmentation_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Rescaling(1.0/255),\n",
        "  tf.keras.layers.RandomBrightness(factor=0.1, value_range=(0,1)),\n",
        "  tf.keras.layers.RandomContrast(factor=0.1),\n",
        "  tf.keras.layers.RandomRotation(factor=0.05, fill_mode='constant'),\n",
        "  tf.keras.layers.RandomTranslation(0.05, 0.05, fill_mode='constant'),\n",
        "  tf.keras.layers.RandomZoom(\n",
        "      height_factor=(-0.05, 0.05),\n",
        "      width_factor=None,\n",
        "      fill_mode='constant'\n",
        "  ),\n",
        "  tf.keras.layers.GaussianNoise(0.01)\n",
        "])\n",
        "\n",
        "@tf.function\n",
        "def augment_with_model(x, y):\n",
        "  cal_imgs, cal_coords, target_imgs = x\n",
        "\n",
        "  # Apply augmentation model\n",
        "  cal_imgs = augmentation_model(cal_imgs, training=True)\n",
        "  target_imgs = augmentation_model(target_imgs, training=True)\n",
        "\n",
        "  return (cal_imgs, cal_coords, target_imgs), y\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.element_spec"
      ],
      "metadata": {
        "id": "CoLt7iT-kdNy",
        "outputId": "dcd92536-52ca-4840-a630-0ca2de91ec4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((TensorSpec(shape=(None, 36, 144, 1), dtype=tf.uint8, name=None),\n",
              "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None),\n",
              "  TensorSpec(shape=(None, 36, 144, 1), dtype=tf.uint8, name=None)),\n",
              " TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "sz_L2j0duJDw"
      },
      "outputs": [],
      "source": [
        "t0 = train_data_rescaled.cache()\n",
        "\n",
        "t1 = t0.group_by_window(\n",
        "    key_func = lambda img, m, c, z: z,\n",
        "    reduce_func = reducer_function,\n",
        "    window_size = 200\n",
        ").prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "t2 = t0.group_by_window(\n",
        "    key_func = lambda img, m, c, z: z,\n",
        "    reduce_func = reducer_function_fixed_pts_with_id,\n",
        "    window_size = 200\n",
        ")\n",
        "\n",
        "# Apply to dataset\n",
        "train_ds = t1.map(\n",
        "    augment_with_model,\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ").prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# v = validation_data_rescaled.group_by_window(\n",
        "#     key_func = lambda img, m, c, z: z,\n",
        "#     reduce_func = reducer_function_fixed_pts_with_id,\n",
        "#     window_size = 200\n",
        "# ).cache().prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORk_yuzTYhS3"
      },
      "source": [
        "## Visualize augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WeTXbm3mYhS3",
        "outputId": "5fe67c07-b86b-4a94-e531-e72d653da441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OperatorNotAllowedInGraphError",
          "evalue": "in user code:\n\n    File \"<ipython-input-33-8d9ae6000671>\", line 18, in augment_with_model  *\n        cal_imgs, cal_coords, target_imgs = x\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-781fb3b72323>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Use this to check your augmentations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mvisualize_augmentations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-781fb3b72323>\u001b[0m in \u001b[0;36mvisualize_augmentations\u001b[0;34m(dataset, num_examples)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Apply augmentation multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0maugmented_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_image_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugment_with_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Display augmented versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[1;32m   2339\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2341\u001b[0;31m     return map_op._map_v2(\n\u001b[0m\u001b[1;32m   2342\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0;34m\"`num_parallel_calls` argument is specified.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       )\n\u001b[0;32m---> 43\u001b[0;31m     return _MapDataset(\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, force_synchronous, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1249\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;31m# Implements PolymorphicFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0;31m# Note: wrapper_helper will apply autograph based on context.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"<ipython-input-33-8d9ae6000671>\", line 18, in augment_with_model  *\n        cal_imgs, cal_coords, target_imgs = x\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def visualize_augmentations(dataset, num_examples=5):\n",
        "    \"\"\"Visualize augmentations from a tf.data.Dataset\"\"\"\n",
        "    # Get a sample image\n",
        "    for x, y in t1.take(1):\n",
        "        sample_image = x[0][0]  # First image in the batch\n",
        "\n",
        "    # Create a figure to display results\n",
        "    plt.figure(figsize=(15, 3))\n",
        "\n",
        "    # Show original (normalized)\n",
        "    plt.subplot(1, num_examples+1, 1)\n",
        "    plt.imshow(sample_image.numpy().squeeze(), cmap='gray')\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Create a dataset with just our sample image\n",
        "    single_image_ds = tf.data.Dataset.from_tensors((sample_image, 0))\n",
        "\n",
        "    # Apply augmentation multiple times\n",
        "    augmented_ds = single_image_ds.repeat(num_examples).map(augment_with_model)\n",
        "\n",
        "    # Display augmented versions\n",
        "    for i, (aug_img, _) in enumerate(augmented_ds.take(num_examples)):\n",
        "        plt.subplot(1, num_examples+1, i+2)\n",
        "        plt.imshow(aug_img.numpy().squeeze(), cmap='gray')\n",
        "        plt.title(f\"Aug {i+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Use this to check your augmentations\n",
        "visualize_augmentations(train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t19yxxx_Ts8H"
      },
      "source": [
        "# Construct Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxuZobSgkgbW"
      },
      "source": [
        "## Eye image processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "GnKs983UsyDj"
      },
      "outputs": [],
      "source": [
        "def create_embedding_model():\n",
        "    input_eyes = keras.layers.Input(shape=(36,144,1))\n",
        "\n",
        "    # Continue with the backbone\n",
        "    backbone = keras_cv.models.DenseNetBackbone(\n",
        "        include_rescaling=False,\n",
        "        input_shape=(36,144,1),\n",
        "        stackwise_num_repeats=DENSE_NET_STACKWISE_NUM_REPEATS\n",
        "    )\n",
        "    backbone_encoder = backbone(input_eyes)\n",
        "\n",
        "    flatten_compress = keras.layers.Flatten()(backbone_encoder)\n",
        "    eye_embedding = keras.layers.Dense(units=EMBEDDING_DIM, activation=\"tanh\")(flatten_compress)\n",
        "\n",
        "    embedding_model = keras.Model(inputs=input_eyes, outputs=eye_embedding, name=\"Eye_Image_Embedding\")\n",
        "\n",
        "    return embedding_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K62VuVwq6lvd"
      },
      "source": [
        "## Regression Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jGk0aRz_ebqk"
      },
      "outputs": [],
      "source": [
        "class WeightedRidgeRegressionLayer(keras.layers.Layer):\n",
        "    def __init__(self, lambda_ridge, epsilon=1e-6, **kwargs):\n",
        "        self.lambda_ridge = lambda_ridge\n",
        "        self.epsilon = epsilon\n",
        "        super(WeightedRidgeRegressionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    @tf.function(jit_compile=True)\n",
        "    def call(self, inputs):\n",
        "        unknown_embeddings, calibration_embeddings, calibration_coords, weights = inputs\n",
        "\n",
        "        X = tf.cast(calibration_embeddings, tf.float32)  # (batch_size, n_calibration, 20)\n",
        "        y = tf.cast(calibration_coords, tf.float32)  # (batch_size, n_calibration, 2)\n",
        "        w = tf.cast(weights, tf.float32)  # (batch_size, n_calibration)\n",
        "\n",
        "        # Add assertions\n",
        "        # tf.debugging.assert_rank(X, 3, \"calibration_embeddings should be rank 3\")\n",
        "        # tf.debugging.assert_rank(y, 3, \"calibration_coords should be rank 3\")\n",
        "        # tf.debugging.assert_rank(w, 2, \"weights should be rank 2\")\n",
        "        # tf.debugging.assert_non_negative(w, \"weights should be non-negative\")\n",
        "        # tf.debugging.assert_less_equal(w, 1.0, \"weights should be less than or equal to 1\")\n",
        "\n",
        "        # Compute weighted ridge regression coefficients\n",
        "        n, p = X.shape[-2:]  # n_calibration, 20\n",
        "        I = tf.eye(p, dtype=X.dtype)\n",
        "\n",
        "        # Apply weights to X and y\n",
        "        w_sqrt = tf.sqrt(w)\n",
        "        X_weighted = X * tf.expand_dims(w_sqrt, axis=-1)  # (batch_size, n_calibration, 20)\n",
        "        y_weighted = y * tf.expand_dims(w_sqrt, axis=-1)  # (batch_size, n_calibration, 2)\n",
        "\n",
        "        X_t = tf.transpose(X_weighted, perm=[0, 2, 1])  # (batch_size, 20, n_calibration)\n",
        "        X_t_X = tf.linalg.matmul(X_t, X_weighted)  # (batch_size, 20, 20)\n",
        "        lhs = X_t_X + (self.lambda_ridge + self.epsilon) * I  # (batch_size, 20, 20)\n",
        "        rhs = tf.linalg.matmul(X_t, y_weighted)  # (batch_size, 20, 2)\n",
        "\n",
        "        kernel = tf.linalg.solve(lhs, rhs)  # (batch_size, 20, 2)\n",
        "\n",
        "        # Apply regression to unknown point\n",
        "        unknown_embeddings = tf.cast(unknown_embeddings, tf.float32)\n",
        "        output = tf.linalg.matmul(unknown_embeddings, tf.transpose(kernel, perm=[0, 2, 1]), adjoint_b=True)  # (batch_size, ?, 2)\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shapes):\n",
        "        unknown_embeddings_shape, _, _, _ = input_shapes\n",
        "        return unknown_embeddings_shape[:-1] + (2,)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(WeightedRidgeRegressionLayer, self).get_config()\n",
        "        config.update({\"lambda_ridge\": self.lambda_ridge, \"epsilon\": self.epsilon})\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "6JOA5GNqTUW-"
      },
      "outputs": [],
      "source": [
        "def create_full_model():\n",
        "\n",
        "  embedding_model = create_embedding_model()\n",
        "\n",
        "  input_calibration_eyes = keras.layers.Input(shape=(None,36,144,1), name=\"Input_Calibration_Eyes\")\n",
        "  input_calibration_points = keras.layers.Input(shape=(None,2,), name=\"Input_Calibration_Points\")\n",
        "\n",
        "  input_target_eyes = keras.layers.Input(shape=(None,36,144,1), name=\"Input_Target_Eyes\")\n",
        "\n",
        "  target_embedding = keras.layers.TimeDistributed(embedding_model)(input_target_eyes)\n",
        "  calibration_embeddings = keras.layers.TimeDistributed(embedding_model)(input_calibration_eyes)\n",
        "\n",
        "  calibration_weights = keras.layers.Dense(1, activation=\"sigmoid\", name=\"Calibration_Weights\")(calibration_embeddings)\n",
        "  calibration_weights_reshaped = keras.layers.Reshape((-1,), name=\"Calibration_Weights_Reshaped\")(calibration_weights)\n",
        "\n",
        "  ridge = WeightedRidgeRegressionLayer(RIDGE_REGULARIZATION)([target_embedding, calibration_embeddings, input_calibration_points, calibration_weights_reshaped])\n",
        "\n",
        "  full_model = keras.Model(inputs=[\n",
        "    input_calibration_eyes,\n",
        "    input_calibration_points,\n",
        "    input_target_eyes\n",
        "  ], outputs=ridge, name=\"FullEyePredictionModel\")\n",
        "\n",
        "  return full_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtm4EUSZwXDC"
      },
      "source": [
        "## Full trainable model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "7xAFsV9x41BZ",
        "outputId": "5dab8f28-be07-4336-ead4-326fec6cbcce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"FullEyePredictionModel\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"FullEyePredictionModel\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Input_Calibration_Eyes    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │ \u001b[38;5;34m1\u001b[0m)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast_12 (\u001b[38;5;33mCast\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │              \u001b[38;5;34m0\u001b[0m │ Input_Calibration_Eye… │\n",
              "│                           │ \u001b[38;5;34m1\u001b[0m)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Input_Target_Eyes         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │ \u001b[38;5;34m1\u001b[0m)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │      \u001b[38;5;34m1,581,896\u001b[0m │ cast_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast_11 (\u001b[38;5;33mCast\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m144\u001b[0m,  │              \u001b[38;5;34m0\u001b[0m │ Input_Target_Eyes[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                           │ \u001b[38;5;34m1\u001b[0m)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Input_Calibration_Points  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Calibration_Weights       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │            \u001b[38;5;34m201\u001b[0m │ time_distributed_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │      \u001b[38;5;34m1,581,896\u001b[0m │ cast_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast_13 (\u001b[38;5;33mCast\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ Input_Calibration_Poi… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Calibration_Weights_Resh… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ Calibration_Weights[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)                 │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ weighted_ridge_regressio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ time_distributed_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mWeightedRidgeRegression…\u001b[0m │                        │                │ time_distributed_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                           │                        │                │ cast_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ Calibration_Weights_R… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Input_Calibration_Eyes    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Input_Calibration_Eye… │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Input_Target_Eyes         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,581,896</span> │ cast_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Input_Target_Eyes[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Input_Calibration_Points  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Calibration_Weights       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │ time_distributed_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,581,896</span> │ cast_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Input_Calibration_Poi… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Calibration_Weights_Resh… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Calibration_Weights[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                 │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ weighted_ridge_regressio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">WeightedRidgeRegression…</span> │                        │                │ time_distributed_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                           │                        │                │ cast_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ Calibration_Weights_R… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,582,097\u001b[0m (6.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,582,097</span> (6.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,574,257\u001b[0m (6.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,257</span> (6.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,840\u001b[0m (30.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,840</span> (30.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "full_model = create_full_model()\n",
        "\n",
        "full_model.summary()\n",
        "\n",
        "full_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss=normalized_weighted_euc_dist,\n",
        "    metrics=[normalized_weighted_euc_dist],\n",
        "    jit_compile = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5FnXA0JueNHm"
      },
      "outputs": [],
      "source": [
        "def lr_schedule(epoch):\n",
        "  if epoch < 15:\n",
        "    return LEARNING_RATE\n",
        "  else:\n",
        "    return LEARNING_RATE * 0.1\n",
        "\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzxl5IX0ycoR"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "t15bFcCV4_yw",
        "outputId": "af9654f7-154d-4c08-f44a-68c2f3568b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1726/1726\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m593s\u001b[0m 320ms/step - loss: 0.2662 - normalized_weighted_euc_dist: 0.2662 - learning_rate: 0.0010\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 169/1726\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:29\u001b[0m 212ms/step - loss: 0.2618 - normalized_weighted_euc_dist: 0.2618"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-dbeeb53f9a08>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWandbMetricsLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#full_model.fit(t1.batch(1), epochs=TRAIN_EPOCHS)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_history = full_model.fit(train_ds.batch(1), epochs=TRAIN_EPOCHS, callbacks=[WandbMetricsLogger(), lr_scheduler])\n",
        "#full_model.fit(t1.batch(1), epochs=TRAIN_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVk3s8vQRFpl"
      },
      "outputs": [],
      "source": [
        "full_model.save('full_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI9SocMbzC5p"
      },
      "outputs": [],
      "source": [
        "full_model.save_weights('full_model.weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZy4iASiRJvi",
        "outputId": "06b52841-04d9-4799-b797-ba1d2fc63367"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/wandb/run-20241221_135150-2rlxy5dx/files/full_model.weights.h5']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.save('full_model.keras')\n",
        "wandb.save('full_model.weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_OUDhetR5LdO",
        "outputId": "51a6252a-2ea1-4d47-806f-08a20a6f3d9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1564/1564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m807s\u001b[0m 421ms/step\n"
          ]
        }
      ],
      "source": [
        "# Initialize a list to store the batch losses\n",
        "batch_losses = []\n",
        "subject_ids = []\n",
        "y_true = []\n",
        "\n",
        "for e in t2.batch(1).as_numpy_iterator():\n",
        "\n",
        "    y_true.append(e[1])\n",
        "    subject_ids.append(e[2][0])\n",
        "\n",
        "y_true = np.array(y_true).reshape(-1, 144, 2)\n",
        "\n",
        "# this step is slower than expected. not sure what's going on.\n",
        "predictions = full_model.predict(t2.batch(1))\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "  loss = normalized_weighted_euc_dist(y_true[i], predictions[i]).numpy()\n",
        "  batch_losses.append(loss)\n",
        "\n",
        "batch_losses = np.array(batch_losses)\n",
        "\n",
        "# Get mean per subject\n",
        "batch_losses = np.mean(batch_losses, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FdB2Anc88Qz"
      },
      "outputs": [],
      "source": [
        "final_loss_table = wandb.Table(data=[[s, l] for (s, l) in zip(subject_ids, batch_losses)], columns=[\"subject\", \"scores\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvKzpmrI9PBO"
      },
      "outputs": [],
      "source": [
        "final_loss_hist = wandb.plot.histogram(final_loss_table, \"scores\", title=\"Normalized Euclidean Distance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9iK_69wdrZ0"
      },
      "outputs": [],
      "source": [
        "final_loss_mean = np.mean(batch_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk8z0iV4DV2d"
      },
      "outputs": [],
      "source": [
        "wandb.log({\"final_val_loss_table\": final_loss_table, \"final_val_loss_hist\": final_loss_hist, \"final_loss_mean\": final_loss_mean})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blgWDH3E5Swd",
        "outputId": "f99d4dea-8b6d-431b-e653-fec7a49caa73"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(batch_losses, bins=20, edgecolor='black')\n",
        "plt.title('Histogram of Batch Losses')\n",
        "plt.xlabel('Loss')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "xXAdVnFKMjg7",
        "outputId": "f270a33d-3e8d-4824-b4a6-55936f6c1a33"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▅▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/normalized_weighted_euc_dist</td><td>█▆▅▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>final_loss_mean</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>29</td></tr><tr><td>epoch/learning_rate</td><td>0.0001</td></tr><tr><td>epoch/loss</td><td>0.04859</td></tr><tr><td>epoch/normalized_weighted_euc_dist</td><td>0.04859</td></tr><tr><td>final_loss_mean</td><td>0.05181</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">devout-meadow-6</strong> at: <a href='https://wandb.ai/eye-tracking/eye-tracking-dense-full-data-set-single-eye/runs/2rlxy5dx' target=\"_blank\">https://wandb.ai/eye-tracking/eye-tracking-dense-full-data-set-single-eye/runs/2rlxy5dx</a><br> View project at: <a href='https://wandb.ai/eye-tracking/eye-tracking-dense-full-data-set-single-eye' target=\"_blank\">https://wandb.ai/eye-tracking/eye-tracking-dense-full-data-set-single-eye</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 3 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241221_135150-2rlxy5dx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}