{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36beac",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.5' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Python38/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install osfclient --quiet\n",
    "!pip install plotnine --quiet\n",
    "!pip install git+https://github.com/jspsych/eyetracking-utils.git --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304da168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "import osfclient\n",
    "\n",
    "import et_util.dataset_utils as dataset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb016bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OSF_TOKEN'] = userdata.get('osftoken')\n",
    "os.environ['OSF_USERNAME'] = userdata.get('osfusername')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903fc9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!osf -p uf2sh fetch single_eye_tfrecords.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir single_eye_tfrecords\n",
    "!tar -xf single_eye_tfrecords.tar.gz -C single_eye_tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to directory containing TFRecord files\n",
    "TFRECORDS_PATH = 'single_eye_tfrecords'\n",
    "\n",
    "# Path to save CSV output\n",
    "OUTPUT_CSV = 'eye_image_quality_metrics.csv'\n",
    "\n",
    "# Maximum number of subjects to process (None for all)\n",
    "MAX_SUBJECTS = 10  # Change to None to process all subjects\n",
    "\n",
    "# OSF token for uploading results (None to skip upload)\n",
    "OSF_TOKEN = None  # Set to your token if you want to upload to OSF\n",
    "\n",
    "# OSF project ID for uploading results\n",
    "OSF_PROJECT_ID = None  # Set to your project ID if you want to upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e6bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(element):\n",
    "    data_structure = {\n",
    "        'landmarks': tf.io.FixedLenFeature([], tf.string),\n",
    "        'img_width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'img_height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'x': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'y': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'eye_img': tf.io.FixedLenFeature([], tf.string),\n",
    "        'phase': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'subject_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    content = tf.io.parse_single_example(element, data_structure)\n",
    "\n",
    "    #landmarks = content['landmarks']\n",
    "    raw_image = content['eye_img']\n",
    "    width = content['img_width']\n",
    "    height = content['img_height']\n",
    "    phase = content['phase']\n",
    "    depth = 3\n",
    "    coords = [content['x'], content['y']]\n",
    "    subject_id = content['subject_id']\n",
    "\n",
    "    image = tf.io.parse_tensor(raw_image, out_type=tf.uint8)\n",
    "\n",
    "    return image, phase, coords, subject_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a52e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, _, _ = dataset_utils.process_tfr_to_tfds(\n",
    "    'single_eye_tfrecords/',\n",
    "    parse,\n",
    "    train_split=1.0,\n",
    "    val_split=0.0,\n",
    "    test_split=0.0,\n",
    "    random_seed=12604,\n",
    "    group_function=lambda img, phase, coords, subject_id: subject_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageQualityMetrics:\n",
    "    \"\"\"Class to calculate various image quality metrics\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_numpy(img_tensor):\n",
    "        \"\"\"Convert TensorFlow tensor to numpy array\"\"\"\n",
    "        if isinstance(img_tensor, tf.Tensor):\n",
    "            img = img_tensor.numpy()\n",
    "        else:\n",
    "            img = img_tensor\n",
    "        # Ensure grayscale images have proper dimensions\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "        return img\n",
    "    \n",
    "    @staticmethod\n",
    "    def brightness(img):\n",
    "        \"\"\"Calculate mean brightness of the image\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        return float(np.mean(img))\n",
    "    \n",
    "    @staticmethod\n",
    "    def contrast(img):\n",
    "        \"\"\"Calculate contrast as standard deviation of pixel values\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        return float(np.std(img))\n",
    "    \n",
    "    @staticmethod\n",
    "    def entropy(img):\n",
    "        \"\"\"Calculate image entropy (information content)\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        img_flat = img.flatten()\n",
    "        hist, _ = np.histogram(img_flat, bins=256, range=(0, 255), density=True)\n",
    "        hist = hist[hist > 0]  # Remove zero counts\n",
    "        return float(-np.sum(hist * np.log2(hist)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def laplacian_variance(img):\n",
    "        \"\"\"Calculate variance of the Laplacian (measure of focus/sharpness)\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        if img.shape[-1] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) \n",
    "        else:\n",
    "            img_gray = img.squeeze()\n",
    "        return float(cv2.Laplacian(img_gray, cv2.CV_64F).var())\n",
    "    \n",
    "    @staticmethod\n",
    "    def gradient_magnitude(img):\n",
    "        \"\"\"Calculate mean gradient magnitude (edge strength)\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        if img.shape[-1] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            img_gray = img.squeeze()\n",
    "        sobelx = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "        return float(np.mean(gradient_magnitude))\n",
    "    \n",
    "    @staticmethod\n",
    "    def blur_detection(img):\n",
    "        \"\"\"Just Noticeable Blur (JNB) measure - higher values indicate less blur\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        if img.shape[-1] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            img_gray = img.squeeze()\n",
    "        \n",
    "        # Apply Laplacian filter\n",
    "        laplacian = cv2.Laplacian(img_gray, cv2.CV_64F)\n",
    "        \n",
    "        # Calculate mean and standard deviation of Laplacian\n",
    "        mean, std = cv2.meanStdDev(laplacian)\n",
    "        \n",
    "        # Calculate normalized blur measure (higher value = less blur)\n",
    "        blur_measure = float(std[0][0]**2)\n",
    "        \n",
    "        return blur_measure\n",
    "    \n",
    "    @staticmethod\n",
    "    def noise_estimation(img):\n",
    "        \"\"\"Estimate image noise level\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        if img.shape[-1] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            img_gray = img.squeeze()\n",
    "        \n",
    "        # Apply median filter (noise reduction)\n",
    "        median_filtered = cv2.medianBlur(img_gray.astype(np.uint8), 3)\n",
    "        \n",
    "        # Calculate noise as difference between original and filtered\n",
    "        noise = np.abs(img_gray - median_filtered)\n",
    "        \n",
    "        return float(np.mean(noise))\n",
    "    \n",
    "    @staticmethod\n",
    "    def local_contrast(img, region_size=5):\n",
    "        \"\"\"Calculate local contrast in eye region\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        if img.shape[-1] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            img_gray = img.squeeze()\n",
    "        \n",
    "        # Assuming eye region is in center - calculate local contrast there\n",
    "        h, w = img_gray.shape\n",
    "        center_y, center_x = h // 2, w // 2\n",
    "        y1 = max(0, center_y - region_size)\n",
    "        y2 = min(h, center_y + region_size)\n",
    "        x1 = max(0, center_x - region_size)\n",
    "        x2 = min(w, center_x + region_size)\n",
    "        \n",
    "        region = img_gray[y1:y2, x1:x2]\n",
    "        return float(np.std(region))\n",
    "    \n",
    "    @staticmethod\n",
    "    def dark_channel_prior(img):\n",
    "        \"\"\"Calculate dark channel prior (often used for haze detection)\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        if img.shape[-1] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            img_gray = img.squeeze()\n",
    "        \n",
    "        # Apply min filter to estimate dark channel\n",
    "        kernel_size = 3\n",
    "        pad_size = kernel_size // 2\n",
    "        padded = np.pad(img_gray, pad_size, mode='edge')\n",
    "        dark_channel = np.zeros_like(img_gray)\n",
    "        \n",
    "        for i in range(img_gray.shape[0]):\n",
    "            for j in range(img_gray.shape[1]):\n",
    "                patch = padded[i:i+kernel_size, j:j+kernel_size]\n",
    "                dark_channel[i, j] = np.min(patch)\n",
    "        \n",
    "        return float(np.mean(dark_channel))\n",
    "    \n",
    "    @staticmethod\n",
    "    def specular_reflection_count(img, threshold=240):\n",
    "        \"\"\"Count potential specular reflections (bright spots)\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        if img.shape[-1] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            img_gray = img.squeeze()\n",
    "        \n",
    "        # Threshold to find bright spots\n",
    "        bright_spots = (img_gray > threshold).astype(np.uint8)\n",
    "        \n",
    "        # Find connected components\n",
    "        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(bright_spots, connectivity=8)\n",
    "        \n",
    "        # Count spots above a minimum size (to ignore noise)\n",
    "        min_area = 5\n",
    "        num_spots = 0\n",
    "        for i in range(1, num_labels):  # Skip background (label 0)\n",
    "            if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "                num_spots += 1\n",
    "        \n",
    "        return num_spots\n",
    "    \n",
    "    @staticmethod\n",
    "    def pupil_detection_score(img):\n",
    "        \"\"\"Estimate how well we can detect a pupil (using basic circle detection)\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        if img.shape[-1] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            img_gray = img.squeeze()\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(img_gray, (5, 5), 0)\n",
    "        \n",
    "        # Use Hough Circle Transform to detect circles\n",
    "        # The parameters may need to be adjusted based on your images\n",
    "        try:\n",
    "            circles = cv2.HoughCircles(\n",
    "                blurred, \n",
    "                cv2.HOUGH_GRADIENT, \n",
    "                dp=1, \n",
    "                minDist=20, \n",
    "                param1=50, \n",
    "                param2=30, \n",
    "                minRadius=5, \n",
    "                maxRadius=25\n",
    "            )\n",
    "            \n",
    "            # Score based on number of circles and strength of detection\n",
    "            if circles is not None:\n",
    "                circles = circles[0]\n",
    "                # Return score based on strength of best circle\n",
    "                if len(circles) > 0:\n",
    "                    return float(circles[0][2])  # Use radius as a proxy for confidence\n",
    "                else:\n",
    "                    return 0.0\n",
    "            else:\n",
    "                return 0.0\n",
    "        except:\n",
    "            # If any error occurs, return 0\n",
    "            return 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_all_metrics(img):\n",
    "        \"\"\"Compute all image quality metrics and return as dictionary\"\"\"\n",
    "        metrics = {\n",
    "            'brightness': ImageQualityMetrics.brightness(img),\n",
    "            'contrast': ImageQualityMetrics.contrast(img),\n",
    "            'entropy': ImageQualityMetrics.entropy(img),\n",
    "            'laplacian_variance': ImageQualityMetrics.laplacian_variance(img),\n",
    "            'gradient_magnitude': ImageQualityMetrics.gradient_magnitude(img),\n",
    "            'blur_detection': ImageQualityMetrics.blur_detection(img),\n",
    "            'noise_estimation': ImageQualityMetrics.noise_estimation(img),\n",
    "            'local_contrast': ImageQualityMetrics.local_contrast(img),\n",
    "            'dark_channel_prior': ImageQualityMetrics.dark_channel_prior(img),\n",
    "            'specular_reflection_count': ImageQualityMetrics.specular_reflection_count(img),\n",
    "            'pupil_detection_score': ImageQualityMetrics.pupil_detection_score(img)\n",
    "        }\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subject_images(dataset, subject_id):\n",
    "    \"\"\"Process all images for a given subject and compute metrics\"\"\"\n",
    "    # Filter dataset to only include this subject\n",
    "    subject_dataset = dataset.filter(lambda img, phase, coords, sid: tf.equal(sid, subject_id))\n",
    "    \n",
    "    # Initialize results\n",
    "    results = []\n",
    "    \n",
    "    # Process each image\n",
    "    for i, (img, phase, coords, _) in enumerate(subject_dataset):\n",
    "        # Convert to numpy and ensure format is correct\n",
    "        img_np = img.numpy()\n",
    "        \n",
    "        # Compute all metrics\n",
    "        metrics = ImageQualityMetrics.compute_all_metrics(img_np)\n",
    "        \n",
    "        # Add metadata\n",
    "        metrics.update({\n",
    "            'subject_id': subject_id.numpy(),\n",
    "            'image_index': i,\n",
    "            'phase': phase.numpy(),\n",
    "            'coord_x': coords[0].numpy(),\n",
    "            'coord_y': coords[1].numpy()\n",
    "        })\n",
    "        \n",
    "        # Append to results\n",
    "        results.append(metrics)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_all_subjects(dataset, subject_ids, max_subjects=None):\n",
    "    \"\"\"Process images for all subjects and save metrics\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    # Limit number of subjects if specified\n",
    "    if max_subjects:\n",
    "        print(f\"Limiting processing to {max_subjects} subjects\")\n",
    "        subject_ids = subject_ids[:max_subjects]\n",
    "    \n",
    "    # Process each subject\n",
    "    for subject_id in tqdm(subject_ids, desc=\"Processing subjects\"):\n",
    "        subject_results = process_subject_images(dataset, tf.constant(subject_id))\n",
    "        all_results.extend(subject_results)\n",
    "        \n",
    "        # Print occasional updates\n",
    "        if len(all_results) % 1000 == 0:\n",
    "            print(f\"Processed {len(all_results)} images so far...\")\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_and_upload_results(df, filename, osf_token=None, osf_project_id=None):\n",
    "    \"\"\"Save results to CSV and upload to OSF if credentials provided\"\"\"\n",
    "    # Save to CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved results to {filename}\")\n",
    "    \n",
    "    # Upload to OSF if credentials provided\n",
    "    if OSF_AVAILABLE and osf_token and osf_project_id:\n",
    "        try:\n",
    "            osf = OSF(token=osf_token)\n",
    "            project = osf.project(osf_project_id)\n",
    "            \n",
    "            # Upload file\n",
    "            with open(filename, 'rb') as f:\n",
    "                project.storage().create_file(filename, f, update=True)\n",
    "            \n",
    "            print(f\"Uploaded {filename} to OSF project {osf_project_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading to OSF: {e}\")\n",
    "    else:\n",
    "        if not OSF_AVAILABLE:\n",
    "            print(\"OSF upload skipped: osfclient not installed\")\n",
    "        else:\n",
    "            print(\"OSF upload skipped: credentials not provided\")\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def visualize_metrics(df, output_file=\"metric_correlations.png\"):\n",
    "    \"\"\"Create visualization of metric correlations\"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = df.select_dtypes(include=[np.number]).drop(\n",
    "        columns=['subject_id', 'image_index', 'phase']).corr()\n",
    "    plt.matshow(correlation_matrix, fignum=1)\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(correlation_matrix.columns)), correlation_matrix.columns, rotation=90)\n",
    "    plt.yticks(range(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
    "    plt.title('Correlation between Image Quality Metrics')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    print(f\"Saved correlation matrix visualization to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process TFRecords\n",
    "dataset = process_tfrecords(TFRECORDS_PATH)\n",
    "\n",
    "# Get list of all unique subject IDs\n",
    "subject_ids = get_subject_id_list(dataset)\n",
    "\n",
    "# Process images for all subjects\n",
    "image_quality_df = process_all_subjects(dataset, subject_ids, max_subjects=MAX_SUBJECTS)\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary statistics of image quality metrics:\")\n",
    "print(image_quality_df.describe())\n",
    "\n",
    "# Save and upload results\n",
    "saved_file = save_and_upload_results(\n",
    "    image_quality_df, \n",
    "    filename=OUTPUT_CSV, \n",
    "    osf_token=OSF_TOKEN, \n",
    "    osf_project_id=OSF_PROJECT_ID\n",
    ")\n",
    "\n",
    "# Visualize relationships between metrics\n",
    "visualize_metrics(image_quality_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
