{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36beac",
   "metadata": {
    "id": "ec36beac"
   },
   "outputs": [],
   "source": [
    "!pip install osfclient --quiet\n",
    "!pip install plotnine --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304da168",
   "metadata": {
    "id": "304da168"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "import osfclient\n",
    "\n",
    "import et_util.dataset_utils as dataset_utils\n",
    "from et_util.dataset_utils import parse_single_eye_tfrecord as parse, rescale_coords_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb016bc",
   "metadata": {
    "id": "2cb016bc"
   },
   "outputs": [],
   "source": [
    "os.environ['OSF_TOKEN'] = userdata.get('osftoken')\n",
    "os.environ['OSF_USERNAME'] = userdata.get('osfusername')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903fc9eb",
   "metadata": {
    "id": "903fc9eb"
   },
   "outputs": [],
   "source": [
    "!osf -p uf2sh fetch single_eye_tfrecords.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbc3e4",
   "metadata": {
    "id": "5ebbc3e4"
   },
   "outputs": [],
   "source": [
    "!mkdir single_eye_tfrecords\n",
    "!tar -xf single_eye_tfrecords.tar.gz -C single_eye_tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e6bfff",
   "metadata": {
    "id": "29e6bfff"
   },
   "outputs": [],
   "source": [
    "from et_util.dataset_utils import parse_single_eye_tfrecord as parse, rescale_coords_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a52e0ad",
   "metadata": {
    "id": "5a52e0ad"
   },
   "outputs": [],
   "source": [
    "test_data, _, _ = dataset_utils.process_tfr_to_tfds(\n",
    "    'single_eye_tfrecords/',\n",
    "    parse,\n",
    "    train_split=1.0,\n",
    "    val_split=0.0,\n",
    "    test_split=0.0,\n",
    "    random_seed=12604,\n",
    "    group_function=lambda img, phase, coords, subject_id: subject_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2adb5",
   "metadata": {
    "id": "e8c2adb5"
   },
   "outputs": [],
   "source": [
    "class ImageQualityMetrics:\n",
    "    \"\"\"Class to calculate various image quality metrics\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def to_numpy(img_tensor):\n",
    "        \"\"\"Convert TensorFlow tensor to numpy array\"\"\"\n",
    "        if isinstance(img_tensor, tf.Tensor):\n",
    "            img = img_tensor.numpy()\n",
    "        else:\n",
    "            img = img_tensor\n",
    "        # Ensure grayscale images have proper dimensions\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "        return img\n",
    "\n",
    "    @staticmethod\n",
    "    def brightness(img):\n",
    "        \"\"\"Calculate mean brightness of the image\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        return float(np.mean(img))\n",
    "\n",
    "    @staticmethod\n",
    "    def contrast(img):\n",
    "        \"\"\"Calculate contrast as standard deviation of pixel values\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        return float(np.std(img))\n",
    "\n",
    "    @staticmethod\n",
    "    def entropy(img):\n",
    "        \"\"\"Calculate image entropy (information content)\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        img_flat = img.flatten()\n",
    "        hist, _ = np.histogram(img_flat, bins=256, range=(0, 255), density=True)\n",
    "        hist = hist[hist > 0]  # Remove zero counts\n",
    "        return float(-np.sum(hist * np.log2(hist)))\n",
    "\n",
    "    @staticmethod\n",
    "    def laplacian_variance(img):\n",
    "        \"\"\"Calculate variance of the Laplacian (measure of focus/sharpness)\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        if img.shape[-1] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            img_gray = img.squeeze()\n",
    "        return float(cv2.Laplacian(img_gray, cv2.CV_64F).var())\n",
    "\n",
    "    @staticmethod\n",
    "    def gradient_magnitude(img):\n",
    "        \"\"\"Calculate mean gradient magnitude (edge strength)\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        if img.shape[-1] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            img_gray = img.squeeze()\n",
    "        sobelx = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "        return float(np.mean(gradient_magnitude))\n",
    "\n",
    "    @staticmethod\n",
    "    def blur_detection(img):\n",
    "        \"\"\"Just Noticeable Blur (JNB) measure - higher values indicate less blur\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        if img.shape[-1] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            img_gray = img.squeeze()\n",
    "\n",
    "        # Apply Laplacian filter\n",
    "        laplacian = cv2.Laplacian(img_gray, cv2.CV_64F)\n",
    "\n",
    "        # Calculate mean and standard deviation of Laplacian\n",
    "        mean, std = cv2.meanStdDev(laplacian)\n",
    "\n",
    "        # Calculate normalized blur measure (higher value = less blur)\n",
    "        blur_measure = float(std[0][0]**2)\n",
    "\n",
    "        return blur_measure\n",
    "\n",
    "    @staticmethod\n",
    "    def noise_estimation(img):\n",
    "        \"\"\"Estimate image noise level\"\"\"\n",
    "        img = ImageQualityMetrics.to_numpy(img)\n",
    "        if img.shape[-1] == 3:\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            img_gray = img.squeeze()\n",
    "\n",
    "        # Apply median filter (noise reduction)\n",
    "        median_filtered = cv2.medianBlur(img_gray.astype(np.uint8), 3)\n",
    "\n",
    "        # Calculate noise as difference between original and filtered\n",
    "        noise = np.abs(img_gray - median_filtered)\n",
    "\n",
    "        return float(np.mean(noise))\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_all_metrics(img):\n",
    "        \"\"\"Compute all image quality metrics and return as dictionary\"\"\"\n",
    "        metrics = {\n",
    "            'brightness': ImageQualityMetrics.brightness(img),\n",
    "            'contrast': ImageQualityMetrics.contrast(img),\n",
    "            'entropy': ImageQualityMetrics.entropy(img),\n",
    "            'laplacian_variance': ImageQualityMetrics.laplacian_variance(img),\n",
    "            'gradient_magnitude': ImageQualityMetrics.gradient_magnitude(img),\n",
    "            'blur_detection': ImageQualityMetrics.blur_detection(img),\n",
    "            'noise_estimation': ImageQualityMetrics.noise_estimation(img),\n",
    "        }\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_data.element_spec"
   ],
   "metadata": {
    "id": "Gf1WhpEojvnc"
   },
   "id": "Gf1WhpEojvnc",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results = []\n",
    "\n",
    "for e in test_data:\n",
    "  img, phase, coords, subject_id = e\n",
    "  np_img = img.numpy()\n",
    "  metrics = ImageQualityMetrics.compute_all_metrics(np_img)\n",
    "  metrics.update({\n",
    "      'subject_id': subject_id.numpy(),\n",
    "      'phase': phase.numpy(),\n",
    "      'coord_x': coords[0].numpy(),\n",
    "      'coord_y': coords[1].numpy()\n",
    "  })\n",
    "\n",
    "  results.append(metrics)"
   ],
   "metadata": {
    "id": "iI-dnEFKj5_B"
   },
   "id": "iI-dnEFKj5_B",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(results)"
   ],
   "metadata": {
    "id": "N7esiDghljnI"
   },
   "id": "N7esiDghljnI",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.to_csv('image-quality-metrics.csv', index=False)"
   ],
   "metadata": {
    "id": "5JIBbfFzlnX_"
   },
   "id": "5JIBbfFzlnX_",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!osf -p uf2sh upload image-quality-metrics.csv image-quality-metrics.csv"
   ],
   "metadata": {
    "id": "Ki1mJjhK43ka"
   },
   "id": "Ki1mJjhK43ka",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "lvD-dQAy9O3j"
   },
   "id": "lvD-dQAy9O3j"
  },
  {
   "cell_type": "code",
   "source": [
    "# summarize metrics by participant, with mean and std\n",
    "# count number of phase 1 and phase 2 images for each\n",
    "\n",
    "df_summary = df.groupby('subject_id').agg({\n",
    "    'brightness': ['mean', 'std'],\n",
    "    'contrast': ['mean', 'std'],\n",
    "    'entropy': ['mean', 'std'],\n",
    "    'laplacian_variance': ['mean', 'std'],\n",
    "    'gradient_magnitude': ['mean', 'std'],\n",
    "    'blur_detection': ['mean', 'std'],\n",
    "    'noise_estimation': ['mean', 'std'],\n",
    "    'phase': lambda x: x.value_counts().to_dict()  # Count phase occurrences\n",
    "})\n",
    "\n",
    "# Flatten MultiIndex columns for better readability\n",
    "df_summary.columns = ['_'.join(col) for col in df_summary.columns]\n",
    "\n",
    "# Rename 'phase' columns for clarity\n",
    "df_summary = df_summary.rename(columns={\n",
    "    'phase_<lambda>': 'phase_counts'\n",
    "})\n",
    "\n",
    "# Extract phase counts into separate columns\n",
    "df_summary['phase_1_count'] = df_summary['phase_counts'].apply(lambda x: x.get(1, 0))\n",
    "df_summary['phase_2_count'] = df_summary['phase_counts'].apply(lambda x: x.get(2, 0))\n",
    "\n",
    "# Drop the original 'phase_counts' column\n",
    "df_summary = df_summary.drop(columns=['phase_counts'])\n",
    "\n",
    "df_summary\n"
   ],
   "metadata": {
    "id": "0jODgJRR9Pdu"
   },
   "id": "0jODgJRR9Pdu",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_summary.to_csv('image-quality-metrics-subject-level.csv')"
   ],
   "metadata": {
    "id": "zxPNFvNR-SMd"
   },
   "id": "zxPNFvNR-SMd",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!osf -p uf2sh upload image-quality-metrics-subject-level.csv image-quality-metrics-subject-level.csv"
   ],
   "metadata": {
    "id": "QOgsnklL-Ws6"
   },
   "id": "QOgsnklL-Ws6",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}