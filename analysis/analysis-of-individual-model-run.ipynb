{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9LAJHmSmF84"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eW4fMCshWBrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d4a2a4-11fa-47a9-9225-d41193b75176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for et_util (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install osfclient --quiet\n",
        "!pip install git+https://{cmikul}:{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}@github.com/jspsych/eyetracking-utils.git --quiet\n",
        "!pip install keras_cv --quiet\n",
        "!pip install plotnine --quiet\n",
        "!pip install wandb --quiet\n",
        "!pip install keras-hub --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SQRQZ3D5Vwqc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import keras\n",
        "import keras_hub\n",
        "from keras import ops\n",
        "import keras_cv\n",
        "from plotnine import ggplot, geom_point, aes, geom_line, geom_boxplot, geom_ribbon, scale_y_reverse, theme_void, scale_x_continuous, scale_color_manual, scale_fill_manual, ylab, xlab, labs, theme, theme_classic, element_text, element_blank, element_line\n",
        "import pandas as pd\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbMetricsLogger\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "import et_util.dataset_utils as dataset_utils\n",
        "import et_util.embedding_preprocessing as embed_pre\n",
        "import et_util.model_layers as model_layers\n",
        "from et_util import experiment_utils\n",
        "from et_util.custom_loss import normalized_weighted_euc_dist\n",
        "from et_util.model_analysis import plot_model_performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8BUzHdPEc-ef"
      },
      "outputs": [],
      "source": [
        "os.environ['WANDB_API_KEY'] = userdata.get('WANDB_API_KEY')\n",
        "os.environ['OSF_TOKEN'] = userdata.get('osftoken')\n",
        "os.environ['OSF_USERNAME'] = userdata.get('osfusername')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er9v9bxBcHc0"
      },
      "source": [
        "# Configure W&B experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9SPGBdleCfbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48481c56-173f-4774-c966-53c719bb7b8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed constants\n",
        "MAX_TARGETS = 288\n",
        "\n",
        "# Config constants\n",
        "EMBEDDING_DIM = 200\n",
        "RIDGE_REGULARIZATION = 0.1\n",
        "TRAIN_EPOCHS = 30\n",
        "MIN_CAL_POINTS = 8\n",
        "MAX_CAL_POINTS = 40\n",
        "\n",
        "BACKBONE = \"densenet\"\n",
        "\n",
        "AUGMENTATION = False\n",
        "\n",
        "INITIAL_LEARNING_RATE = 0.00001\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 5\n",
        "TRAIN_EPOCHS = 40\n",
        "WARMUP_EPOCHS = 2\n",
        "DECAY_EPOCHS = TRAIN_EPOCHS - WARMUP_EPOCHS\n",
        "DECAY_ALPHA = 0.01"
      ],
      "metadata": {
        "id": "WQwNaBoP1T9O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKeHGiFxtvo0"
      },
      "source": [
        "# Dataset preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset from OSF (Different from trick model set)"
      ],
      "metadata": {
        "id": "b2DUvhFF9oXr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tswV6s38WbtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d859d3be-7717-423c-c816-4de279e71f8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 388M/388M [00:21<00:00, 18.1Mbytes/s]\n"
          ]
        }
      ],
      "source": [
        "!osf -p uf2sh fetch single_eye_tfrecords.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFgWOhWTt4iD"
      },
      "source": [
        "# Process raw data records into TF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G4h8QhGvWhZf"
      },
      "outputs": [],
      "source": [
        "!mkdir single_eye_tfrecords\n",
        "!tar -xf single_eye_tfrecords.tar.gz -C single_eye_tfrecords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dZRcQgPadqtI"
      },
      "outputs": [],
      "source": [
        "def parse(element):\n",
        "    data_structure = {\n",
        "        'landmarks': tf.io.FixedLenFeature([], tf.string),\n",
        "        'img_width': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'img_height': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'x': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'y': tf.io.FixedLenFeature([], tf.float32),\n",
        "        'eye_img': tf.io.FixedLenFeature([], tf.string),\n",
        "        'phase': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'subject_id': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "\n",
        "    content = tf.io.parse_single_example(element, data_structure)\n",
        "\n",
        "    #landmarks = content['landmarks']\n",
        "    raw_image = content['eye_img']\n",
        "    width = content['img_width']\n",
        "    height = content['img_height']\n",
        "    phase = content['phase']\n",
        "    depth = 3\n",
        "    coords = [content['x'], content['y']]\n",
        "    subject_id = content['subject_id']\n",
        "\n",
        "    # landmarks = tf.io.parse_tensor(landmarks, out_type=tf.float32)\n",
        "    # landmarks = tf.reshape(landmarks, shape=(478, 3))\n",
        "\n",
        "    image = tf.io.parse_tensor(raw_image, out_type=tf.uint8)\n",
        "\n",
        "    return image, phase, coords, subject_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JWv57eb5XHVP"
      },
      "outputs": [],
      "source": [
        "test_data, _, _ = dataset_utils.process_tfr_to_tfds(\n",
        "    'single_eye_tfrecords/',\n",
        "    parse,\n",
        "    train_split=1.0,\n",
        "    val_split=0.0,\n",
        "    test_split=0.0,\n",
        "    random_seed=12604,\n",
        "    group_function=lambda img, phase, coords, subject_id: subject_id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for e in test_data.take(1):\n",
        "  print(e[3])"
      ],
      "metadata": {
        "id": "zAW_l3lX6p9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc62a5a2-f0dc-49f8-df9e-f7e6f87e8274"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(60722210910, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FULm58Cxu9oa"
      },
      "source": [
        "## Rescale the `x,y` coordinates to be 0-1 instead of 0-100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "apcLK9klHLQV"
      },
      "outputs": [],
      "source": [
        "def rescale_coords_map(img, phase, coords, id):\n",
        "  return img, phase, tf.divide(coords, tf.constant([100.])), id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "b47CtWKqHg0B"
      },
      "outputs": [],
      "source": [
        "test_data_rescaled = test_data.map(rescale_coords_map)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for e in test_data_rescaled.take(1):\n",
        "  print(e[3])"
      ],
      "metadata": {
        "id": "XcxmJZnE6zbE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbbc038b-bed9-48b6-87e0-9534d087f624"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(60722210910, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepared masked dataset with phase calibration info"
      ],
      "metadata": {
        "id": "8KfcIpyMrybH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_masked_dataset(dataset, calibration_points=None, cal_phase=None):\n",
        "    # Step 1: Group dataset by subject_id and batch all images\n",
        "    def group_by_subject(subject_id, ds):\n",
        "        return ds.batch(batch_size=MAX_TARGETS)\n",
        "\n",
        "    grouped_dataset = dataset.group_by_window(\n",
        "        key_func=lambda img, phase, coords, subject_id: subject_id,\n",
        "        reduce_func=group_by_subject,\n",
        "        window_size=MAX_TARGETS\n",
        "    )\n",
        "\n",
        "    # Step 2: Filter out subjects with not enough data points （288 total; 144 in each phase)\n",
        "    def filter_by_image_count(images, phase, coords, subject_ids):\n",
        "        total_image_count = tf.shape(images)[0] >= MAX_TARGETS\n",
        "        phase1_image_count = tf.reduce_sum(tf.cast(tf.equal(phase, 1), tf.int32)) >= 144\n",
        "        phase2_image_count = tf.reduce_sum(tf.cast(tf.equal(phase, 2), tf.int32)) >= 144\n",
        "        return tf.logical_and(total_image_count, tf.logical_and(phase1_image_count, phase2_image_count))\n",
        "\n",
        "   # grouped_dataset = grouped_dataset.filter(filter_by_image_count)\n",
        "\n",
        "    # Step 3: Transform each batch to include masks\n",
        "    def add_masks_to_batch(images, phase, coords, subject_ids):\n",
        "\n",
        "        actual_batch_size = tf.shape(images)[0] # how many total images for a given subject\n",
        "\n",
        "        # Create phase masks\n",
        "        phase1_mask = tf.cast(tf.equal(phase, 1), tf.int8)\n",
        "        phase2_mask = tf.cast(tf.equal(phase, 2), tf.int8)\n",
        "\n",
        "        cal_mask = tf.zeros(actual_batch_size, dtype=tf.int8)\n",
        "        target_mask = tf.zeros(actual_batch_size, dtype=tf.int8)\n",
        "\n",
        "        if calibration_points is None:\n",
        "          n_cal_images = tf.random.uniform(\n",
        "              shape=[],\n",
        "              minval=MIN_CAL_POINTS,\n",
        "              maxval=MAX_CAL_POINTS,\n",
        "              dtype=tf.int32\n",
        "          )\n",
        "          random_indices = tf.random.shuffle(tf.range(actual_batch_size))\n",
        "          cal_indices = random_indices[:n_cal_images]\n",
        "\n",
        "          cal_mask = tf.scatter_nd(\n",
        "              tf.expand_dims(cal_indices, 1),\n",
        "              tf.ones(n_cal_images, dtype=tf.int8),\n",
        "              [MAX_TARGETS]\n",
        "          )\n",
        "        else:\n",
        "          coords_xpand = tf.expand_dims(coords, axis=1)\n",
        "          cal_xpand = tf.expand_dims(calibration_points, axis=0)\n",
        "\n",
        "          # Check which points match calibration points\n",
        "          equality = tf.equal(coords_xpand, cal_xpand)\n",
        "          matches = tf.reduce_all(equality, axis=-1)\n",
        "          point_matches = tf.reduce_any(matches, axis=1)\n",
        "          cal_mask = tf.cast(point_matches, dtype=tf.int8)\n",
        "\n",
        "        if cal_phase == 1:\n",
        "          cal_mask = cal_mask * phase1_mask\n",
        "        elif cal_phase == 2:\n",
        "          cal_mask = cal_mask * phase2_mask\n",
        "\n",
        "        target_mask = (1 - cal_mask) * phase2_mask\n",
        "\n",
        "        padded_images = tf.pad(\n",
        "            tf.reshape(images, (-1, 36, 144, 1)),\n",
        "            [[0, MAX_TARGETS - actual_batch_size], [0, 0], [0, 0], [0, 0]]\n",
        "        )\n",
        "        padded_coords = tf.pad(\n",
        "            coords,\n",
        "            [[0, MAX_TARGETS - actual_batch_size], [0, 0]]\n",
        "        )\n",
        "        padded_cal_mask = tf.pad(\n",
        "            cal_mask,\n",
        "            [[0, MAX_TARGETS - actual_batch_size]]\n",
        "        )\n",
        "        padded_target_mask = tf.pad(\n",
        "            target_mask,\n",
        "            [[0, MAX_TARGETS - actual_batch_size]]\n",
        "        )\n",
        "\n",
        "        padded_images = tf.ensure_shape(padded_images, [MAX_TARGETS, 36, 144, 1])\n",
        "        padded_coords = tf.ensure_shape(padded_coords, [MAX_TARGETS, 2])\n",
        "        padded_cal_mask = tf.ensure_shape(padded_cal_mask, [MAX_TARGETS])\n",
        "        padded_target_mask = tf.ensure_shape(padded_target_mask, [MAX_TARGETS])\n",
        "        return (padded_images, padded_coords, padded_cal_mask, padded_target_mask), padded_coords, subject_ids[0]\n",
        "\n",
        "    masked_dataset = grouped_dataset.map(\n",
        "        lambda imgs, phase, coords, subj_ids: add_masks_to_batch(imgs, phase, coords, subj_ids),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    return masked_dataset"
      ],
      "metadata": {
        "id": "jfdmO7MKba7M"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subject_id_list(features, labels, subject_ids):\n",
        "  return subject_ids"
      ],
      "metadata": {
        "id": "aNC0iCcH5pLS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_model_inputs(features, labels, subject_ids):\n",
        "    images, coords, cal_mask, target_mask = features\n",
        "\n",
        "    inputs = {\n",
        "        \"Input_All_Images\": images,\n",
        "        \"Input_All_Coords\": coords,\n",
        "        \"Input_Calibration_Mask\": cal_mask,\n",
        "        \"Input_Target_Mask\": target_mask\n",
        "    }\n",
        "\n",
        "    return inputs, labels, target_mask"
      ],
      "metadata": {
        "id": "WntiqEBSCeOK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cal_points = tf.constant([\n",
        "    [5, 5],\n",
        "    [5, 27.5],\n",
        "    [5, 50],\n",
        "    [5, 72.5],\n",
        "    [5, 95],\n",
        "    [35, 5],\n",
        "    [35, 27.5],\n",
        "    [35, 50],\n",
        "    [35, 72.5],\n",
        "    [35, 95],\n",
        "    [65, 5],\n",
        "    [65, 27.5],\n",
        "    [65, 50],\n",
        "    [65, 72.5],\n",
        "    [65, 95],\n",
        "    [95, 5],\n",
        "    [95, 27.5],\n",
        "    [95, 50],\n",
        "    [95, 72.5],\n",
        "    [95, 95],\n",
        "], dtype=tf.float32)\n",
        "\n",
        "scaled_cal_points = tf.divide(cal_points, tf.constant([100.]))"
      ],
      "metadata": {
        "id": "fgurOg1cq4T8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_dataset_phase1_cal = prepare_masked_dataset(test_data_rescaled, scaled_cal_points, 1)\n",
        "\n",
        "masked_dataset_phase2_cal = prepare_masked_dataset(test_data_rescaled, scaled_cal_points, 2)\n",
        "\n",
        "masked_dataset_subject_ids = masked_dataset_phase1_cal.map(get_subject_id_list)"
      ],
      "metadata": {
        "id": "0gac_vkwbfZq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subject_ids = []\n",
        "for e in masked_dataset_subject_ids.as_numpy_iterator():\n",
        "  subject_ids.append(e)"
      ],
      "metadata": {
        "id": "WWbgci8A55XL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds_phase1_cal = masked_dataset_phase1_cal.map(\n",
        "    prepare_model_inputs,\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ").prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds_phase2_cal = masked_dataset_phase2_cal.map(\n",
        "    prepare_model_inputs,\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ").prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "GlHsEEq0D1Jj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Should be the same for either phase cal choices\n",
        "INDIVIDUALS = 0\n",
        "for e in test_ds_phase1_cal.as_numpy_iterator():\n",
        "  INDIVIDUALS += 1"
      ],
      "metadata": {
        "id": "mzwFyg1cD3ZA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INDIVIDUALS"
      ],
      "metadata": {
        "id": "GsI3d1_Kut8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff701b06-6d93-4332-e685-40cf14fc3690"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "146"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgNRPZIhncRM"
      },
      "source": [
        "# Download the Model Config and Weights File from W&B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1p_UXl0Unfsc"
      },
      "outputs": [],
      "source": [
        "api = wandb.Api()\n",
        "\n",
        "run = api.run(\"vassar-cogsci-lab/eye-tracking-dense-full-data-set-single-eye/v0lc4agm\")\n",
        "\n",
        "config = run.config\n",
        "run.file(\"full_model.weights.h5\").download(exist_ok=True)\n",
        "\n",
        "EMBEDDING_DIM = config[\"embedding_dim\"]\n",
        "RIDGE_REGULARIZATION = config[\"ridge_regularization\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t19yxxx_Ts8H"
      },
      "source": [
        "# Re-construct Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom layers"
      ],
      "metadata": {
        "id": "Ow5T7cNRCHb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTimeDistributed(keras.layers.Wrapper):\n",
        "    def __init__(self, layer, **kwargs):\n",
        "        super().__init__(layer, **kwargs)\n",
        "        self.supports_masking = getattr(layer, 'supports_masking', False)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if not isinstance(input_shape, (tuple, list)) or len(input_shape) < 3:\n",
        "            raise ValueError(\n",
        "                \"`SimpleTimeDistributed` requires input with at least 3 dimensions\"\n",
        "            )\n",
        "\n",
        "        super().build((input_shape[0], *input_shape[2:]))\n",
        "        self.built = True\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        child_output_shape = self.layer.compute_output_shape((input_shape[0], *input_shape[2:]))\n",
        "        return (child_output_shape[0], input_shape[1], *child_output_shape[1:])\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        input_shape = ops.shape(inputs)\n",
        "        batch_size = input_shape[0]\n",
        "        time_steps = input_shape[1]\n",
        "\n",
        "        reshaped_inputs = ops.reshape(inputs, (-1, *input_shape[2:]))\n",
        "\n",
        "        outputs = self.layer.call(reshaped_inputs, training=training)\n",
        "\n",
        "        output_shape = ops.shape(outputs)\n",
        "\n",
        "        return ops.reshape(outputs, (batch_size, time_steps, *output_shape[1:]))"
      ],
      "metadata": {
        "id": "7eXv-aXgnmyt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jGk0aRz_ebqk"
      },
      "outputs": [],
      "source": [
        "class MaskedWeightedRidgeRegressionLayer(keras.layers.Layer):\n",
        "    def __init__(self, lambda_ridge, epsilon=1e-6, **kwargs):\n",
        "        self.lambda_ridge = lambda_ridge\n",
        "        self.epsilon = epsilon\n",
        "        super(MaskedWeightedRidgeRegressionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        embeddings, coords, calibration_weights, cal_mask  = inputs\n",
        "\n",
        "        embeddings = ops.cast(embeddings, \"float32\")\n",
        "        coords = ops.cast(coords, \"float32\")\n",
        "        calibration_weights = ops.cast(calibration_weights, \"float32\")\n",
        "        cal_mask = ops.cast(cal_mask, \"float32\")\n",
        "\n",
        "        w = ops.squeeze(calibration_weights, axis=-1)\n",
        "\n",
        "        w_masked = w * cal_mask\n",
        "        w_sqrt = ops.sqrt(w_masked + self.epsilon)\n",
        "        w_sqrt = ops.expand_dims(w_sqrt, -1)\n",
        "\n",
        "        cal_mask_expand = ops.expand_dims(cal_mask, -1)\n",
        "        X = embeddings * cal_mask_expand\n",
        "\n",
        "        X_weighted = X * w_sqrt\n",
        "        y_weighted = coords * w_sqrt * cal_mask_expand\n",
        "\n",
        "        X_t = ops.transpose(X_weighted, axes=[0, 2, 1])\n",
        "        X_t_X = ops.matmul(X_t, X_weighted)\n",
        "\n",
        "        identity_matrix = ops.cast(ops.eye(ops.shape(embeddings)[-1]), \"float32\")\n",
        "        lhs = X_t_X + self.lambda_ridge * identity_matrix\n",
        "\n",
        "        rhs = ops.matmul(X_t, y_weighted)\n",
        "\n",
        "        kernel = tf.linalg.solve(lhs, rhs)\n",
        "\n",
        "        output = ops.matmul(embeddings, kernel)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def compute_output_shape(self, input_shapes):\n",
        "        unknown_embeddings_shape, _, _, _ = input_shapes\n",
        "        return unknown_embeddings_shape[:-1] + (2,)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(MaskedWeightedRidgeRegressionLayer, self).get_config()\n",
        "        config.update({\"lambda_ridge\": self.lambda_ridge, \"epsilon\": self.epsilon})\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskInspectorLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MaskInspectorLayer, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "    def call(self, inputs, mask=None):\n",
        "      tf.print(\"Layer mask:\", mask)\n",
        "      return inputs"
      ],
      "metadata": {
        "id": "rqTTR5I9n0de"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom loss"
      ],
      "metadata": {
        "id": "qCIOW0_pEIjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalized_weighted_euc_dist(y_true, y_pred):\n",
        "    x_weight = ops.convert_to_tensor([1.778, 1.0], dtype=\"float32\")\n",
        "\n",
        "    y_true_weighted = ops.multiply(x_weight, y_true)\n",
        "    y_pred_weighted = ops.multiply(x_weight, y_pred)\n",
        "\n",
        "    squared_diff = ops.square(y_pred_weighted - y_true_weighted)\n",
        "    squared_dist = ops.sum(squared_diff, axis=-1)\n",
        "    dist = ops.sqrt(squared_dist)\n",
        "\n",
        "    normalized_dist = ops.divide(dist, .0203992)\n",
        "\n",
        "    return normalized_dist"
      ],
      "metadata": {
        "id": "LO6UVbVvyZLM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxuZobSgkgbW"
      },
      "source": [
        "## Embedding model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dense_net_backbone():\n",
        "  DENSE_NET_STACKWISE_NUM_REPEATS = [4,4,4]\n",
        "  return keras_hub.models.DenseNetBackbone(\n",
        "      stackwise_num_repeats=DENSE_NET_STACKWISE_NUM_REPEATS,\n",
        "      image_shape=(36, 144, 1),\n",
        "  )"
      ],
      "metadata": {
        "id": "ue5oH-yT4y20"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GnKs983UsyDj"
      },
      "outputs": [],
      "source": [
        "def create_embedding_model(BACKBONE):\n",
        "  image_shape = (36, 144, 1)\n",
        "  input_eyes = keras.layers.Input(shape=image_shape)\n",
        "\n",
        "  eyes_rescaled = keras.layers.Rescaling(scale=1./255)(input_eyes)\n",
        "\n",
        "  # Continue with the backbone\n",
        "  # backbone = create_rednet_backbone()\n",
        "\n",
        "\n",
        "  # backbone = keras.Sequential([\n",
        "  #     keras.layers.Flatten(),\n",
        "  #     keras.layers.Dense(10, activation=\"relu\")\n",
        "  # ])\n",
        "  if BACKBONE == \"densenet\":\n",
        "    backbone = create_dense_net_backbone()\n",
        "\n",
        "  # backbone = create_efficientnet_backbone()\n",
        "\n",
        "  # backbone = keras_hub.models.MiTBackbone(\n",
        "  #   image_shape=(36,144,1),\n",
        "  #   layerwise_depths=[2,2,2,2],\n",
        "  #   num_layers=4,\n",
        "  #   layerwise_num_heads=[1,2,5,8],\n",
        "  #   layerwise_sr_ratios=[8,4,2,1],\n",
        "  #   max_drop_path_rate=0.1,\n",
        "  #   layerwise_patch_sizes=[7,3,3,3],\n",
        "  #   layerwise_strides=[4,2,2,2],\n",
        "  #   hidden_dims=[32,64,160,256]\n",
        "  # )\n",
        "\n",
        "  backbone_encoder = backbone(eyes_rescaled)\n",
        "  flatten_compress = keras.layers.Flatten()(backbone_encoder)\n",
        "  eye_embedding = keras.layers.Dense(units=EMBEDDING_DIM, activation=\"tanh\")(flatten_compress)\n",
        "\n",
        "  embedding_model = keras.Model(inputs=input_eyes, outputs=eye_embedding, name=\"Eye_Image_Embedding\")\n",
        "\n",
        "  return embedding_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtm4EUSZwXDC"
      },
      "source": [
        "## Full trainable model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6JOA5GNqTUW-"
      },
      "outputs": [],
      "source": [
        "def create_masked_model():\n",
        "    input_all_images = keras.layers.Input(\n",
        "        shape=(MAX_TARGETS, 36, 144, 1),\n",
        "        name=\"Input_All_Images\"\n",
        "    )\n",
        "\n",
        "    input_all_coords = keras.layers.Input(\n",
        "        shape=(MAX_TARGETS, 2),\n",
        "        name=\"Input_All_Coords\"\n",
        "    )\n",
        "\n",
        "    input_cal_mask = keras.layers.Input(\n",
        "        shape=(MAX_TARGETS,),\n",
        "        name=\"Input_Calibration_Mask\",\n",
        "    )\n",
        "\n",
        "    embedding_model = create_embedding_model(BACKBONE)\n",
        "\n",
        "    all_embeddings = SimpleTimeDistributed(embedding_model, name=\"Image_Embeddings\")(input_all_images)\n",
        "\n",
        "    calibration_weights = keras.layers.Dense(\n",
        "        1,\n",
        "        activation=\"sigmoid\",\n",
        "        name=\"Calibration_Weights\"\n",
        "    )(all_embeddings)\n",
        "\n",
        "    ridge = MaskedWeightedRidgeRegressionLayer(\n",
        "        RIDGE_REGULARIZATION,\n",
        "        name=\"Regression\"\n",
        "    )(\n",
        "        [\n",
        "            all_embeddings,\n",
        "            input_all_coords,\n",
        "            calibration_weights,\n",
        "            input_cal_mask,\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    full_model = keras.Model(\n",
        "        inputs=[\n",
        "            input_all_images,\n",
        "            input_all_coords,\n",
        "            input_cal_mask,\n",
        "        ],\n",
        "        outputs=ridge,\n",
        "        name=\"MaskedEyePredictionModel\"\n",
        "    )\n",
        "\n",
        "    return full_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7xAFsV9x41BZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "70c0a27e-a3c3-4670-a66e-842835e0b8a2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"MaskedEyePredictionModel\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MaskedEyePredictionModel\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Input_All_Images          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m144\u001b[0m,   │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │ \u001b[38;5;34m1\u001b[0m)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Image_Embeddings          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │      \u001b[38;5;34m1,581,896\u001b[0m │ Input_All_Images[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mSimpleTimeDistributed\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Input_All_Coords          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Calibration_Weights       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │            \u001b[38;5;34m201\u001b[0m │ Image_Embeddings[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Input_Calibration_Mask    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Regression                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ Image_Embeddings[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMaskedWeightedRidgeRegr…\u001b[0m │                        │                │ Input_All_Coords[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ Calibration_Weights[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ Input_Calibration_Mas… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Input_All_Images          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Image_Embeddings          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,581,896</span> │ Input_All_Images[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleTimeDistributed</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Input_All_Coords          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Calibration_Weights       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │ Image_Embeddings[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Input_Calibration_Mask    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Regression                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Image_Embeddings[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaskedWeightedRidgeRegr…</span> │                        │                │ Input_All_Coords[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ Calibration_Weights[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ Input_Calibration_Mas… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,582,097\u001b[0m (6.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,582,097</span> (6.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,574,257\u001b[0m (6.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,257</span> (6.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,840\u001b[0m (30.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,840</span> (30.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "full_model = create_masked_model()\n",
        "full_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_model.load_weights('full_model.weights.h5')\n",
        "full_model.summary()\n",
        "\n",
        "full_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=normalized_weighted_euc_dist,\n",
        "    metrics=[normalized_weighted_euc_dist],\n",
        "    jit_compile = False\n",
        ")"
      ],
      "metadata": {
        "id": "dRGwIhvnXBOa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "21070cb1-eeb2-460e-bac6-b2e0d48e6292"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"MaskedEyePredictionModel\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MaskedEyePredictionModel\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Input_All_Images          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m144\u001b[0m,   │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │ \u001b[38;5;34m1\u001b[0m)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Image_Embeddings          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │      \u001b[38;5;34m1,581,896\u001b[0m │ Input_All_Images[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mSimpleTimeDistributed\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Input_All_Coords          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Calibration_Weights       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │            \u001b[38;5;34m201\u001b[0m │ Image_Embeddings[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Input_Calibration_Mask    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Regression                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ Image_Embeddings[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMaskedWeightedRidgeRegr…\u001b[0m │                        │                │ Input_All_Coords[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ Calibration_Weights[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ Input_Calibration_Mas… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Input_All_Images          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>,   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Image_Embeddings          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,581,896</span> │ Input_All_Images[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleTimeDistributed</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Input_All_Coords          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Calibration_Weights       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │ Image_Embeddings[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Input_Calibration_Mask    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ Regression                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Image_Embeddings[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaskedWeightedRidgeRegr…</span> │                        │                │ Input_All_Coords[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ Calibration_Weights[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ Input_Calibration_Mas… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,582,097\u001b[0m (6.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,582,097</span> (6.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,574,257\u001b[0m (6.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,257</span> (6.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,840\u001b[0m (30.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,840</span> (30.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzxl5IX0ycoR"
      },
      "source": [
        "# Get model predictions on val data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1 calibration loss distribution across subjects"
      ],
      "metadata": {
        "id": "HNdqPsia_lwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_phase1 = full_model.predict(test_ds_phase1_cal.batch(BATCH_SIZE))"
      ],
      "metadata": {
        "id": "GQJEayJ_yQvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds_phase1_cal.batch(1)"
      ],
      "metadata": {
        "id": "Uxb-nupIorp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_OUDhetR5LdO"
      },
      "outputs": [],
      "source": [
        "# Initialize a list to store the batch losses\n",
        "batch_losses_phase1 = []\n",
        "\n",
        "for pred_batch, ds_batch in zip(predictions_phase1, test_ds_phase1_cal.batch(1).as_numpy_iterator()):\n",
        "    # Extract ground truth and subject ID from dataset batch\n",
        "    y_true = ds_batch[1]\n",
        "    mask = ds_batch[0]['Input_Target_Mask'].reshape(-1)\n",
        "\n",
        "    # Calculate losses for all points in this batch\n",
        "    batch_point_losses = normalized_weighted_euc_dist(y_true, pred_batch).numpy().reshape(-1)\n",
        "    batch_point_losses = batch_point_losses[mask == 1]\n",
        "\n",
        "    # Store average loss for this batch and subject ID\n",
        "    batch_losses_phase1.append(batch_point_losses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_losses_phase1[0]"
      ],
      "metadata": {
        "id": "6Lg_j6H4p_W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subj_avg_losses_phase1 = [np.mean(losses) for losses in batch_losses_phase1]"
      ],
      "metadata": {
        "id": "Jb8IhRMw1j9x",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blgWDH3E5Swd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "n, bins, patches = plt.hist(subj_avg_losses_phase1, bins=np.arange(1,23, 1), color='#333', edgecolor='white')\n",
        "plt.title('Distribution of Model Error (Calibration with Phase 1 Points)')\n",
        "plt.xlabel('Avg. Error - Proportion of Screen Diagonal')\n",
        "plt.ylabel('# subjects')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2 calibration loss distribution across subjects"
      ],
      "metadata": {
        "id": "Jb1Sy-ET_pF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_phase2 = full_model.predict(test_ds_phase2_cal.batch(BATCH_SIZE))"
      ],
      "metadata": {
        "id": "Mr68-eUzsSLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSfQ2msf_DrL"
      },
      "outputs": [],
      "source": [
        "# Initialize a list to store the batch losses\n",
        "batch_losses_phase2 = []\n",
        "subject_ids_phase2 = []\n",
        "\n",
        "for pred_batch, ds_batch in zip(predictions_phase2, test_ds_phase2_cal.batch(1).as_numpy_iterator()):\n",
        "    # Extract ground truth and subject ID from dataset batch\n",
        "    y_true = ds_batch[1]\n",
        "    subject_id = ds_batch[2][0]\n",
        "    mask = ds_batch[0]['Input_Target_Mask'].reshape(-1)\n",
        "\n",
        "    # Calculate losses for all points in this batch\n",
        "    batch_point_losses = normalized_weighted_euc_dist(y_true, pred_batch).numpy().reshape(-1)\n",
        "    batch_point_losses = batch_point_losses[mask == 1]\n",
        "\n",
        "    # Store average loss for this batch and subject ID\n",
        "    batch_losses_phase2.append(batch_point_losses)\n",
        "    subject_ids_phase2.append(subject_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subj_avg_losses_phase2 = [np.mean(losses) for losses in batch_losses_phase2]"
      ],
      "metadata": {
        "id": "CQYwc_00W1Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "n, bins, patches = plt.hist(subj_avg_losses_phase2, bins=np.arange(1,23,1), color='#333', edgecolor='white')\n",
        "plt.title('Distribution of Model Error (Calibration with Phase 2 Points)')\n",
        "plt.xlabel('Avg. Error - Proportion of Screen Diagonal')\n",
        "plt.ylabel('# subjects')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RqmBGZtcWyG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIxNESdIRyue"
      },
      "source": [
        "# Explore model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjjMINThRkLa"
      },
      "outputs": [],
      "source": [
        "val_subj_loss_phase1 = pd.DataFrame(columns=[\"subject_id\", \"loss\"])\n",
        "val_subj_loss_phase1[\"subject_id\"] = subject_ids\n",
        "val_subj_loss_phase1[\"loss\"] = batch_losses_phase1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_subj_loss_phase2 = pd.DataFrame(columns=[\"subject_id\", \"loss\"])\n",
        "val_subj_loss_phase2[\"subject_id\"] = subject_ids\n",
        "val_subj_loss_phase2[\"loss\"] = batch_losses_phase2"
      ],
      "metadata": {
        "id": "hZwcNgtOJimX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_subj_loss_phase1['loss'] = val_subj_loss_phase1['loss'].apply(np.mean)\n",
        "val_subj_loss_phase2['loss'] = val_subj_loss_phase2['loss'].apply(np.mean)"
      ],
      "metadata": {
        "id": "dImxtTxp_f9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calibration with phase 1 points vs phase 2 points for one subject (biggest diff subject chosen)"
      ],
      "metadata": {
        "id": "fUYCt444t267"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(val_subj_loss_phase1[val_subj_loss_phase1['loss'] <= 25], val_subj_loss_phase2[val_subj_loss_phase2['loss'] <= 25], on='subject_id', suffixes=('_phase1', '_phase2'))\n",
        "merged_df['loss_diff'] = abs(merged_df['loss_phase1'] - merged_df['loss_phase2'])\n",
        "\n",
        "max_diff_row_idx = merged_df['loss_diff'].idxmax()\n",
        "max_diff_row = merged_df.loc[max_diff_row_idx]\n",
        "max_diff_row_subject_id = max_diff_row['subject_id']"
      ],
      "metadata": {
        "id": "UShx-0nyJnOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cw-OsZcNTMR_"
      },
      "outputs": [],
      "source": [
        "v_predictions_phase1 = full_model.predict(test_ds_phase1_cal.skip(max_diff_row_subject_id).take(1).batch(1))[0]\n",
        "\n",
        "v_pts_phase1 = []\n",
        "\n",
        "for e in test_ds_phase1_cal.skip(max_diff_row_idx).take(1).as_numpy_iterator():\n",
        "  v_pts_phase1 = e[1]\n",
        "\n",
        "v_errors_phase1 = np.linalg.norm(v_predictions_phase1 - v_pts_phase1, axis=1)\n",
        "\n",
        "dfA_phase1 = pd.DataFrame({\"sample\": range(len(v_pts_phase1)), \"x\": v_pts_phase1[:,0], \"y\": v_pts_phase1[:,1], \"error\": v_errors_phase1, \"point_type\": \"target\"})\n",
        "dfB_phase1 = pd.DataFrame({\"sample\": range(len(v_pts_phase1)), \"x\": v_predictions_phase1[:,0], \"y\": v_predictions_phase1[:,1], \"error\": v_errors_phase1, \"point_type\": \"prediction\"})\n",
        "\n",
        "v_df_phase1 = pd.concat([dfA_phase1,dfB_phase1])\n",
        "\n",
        "(ggplot(v_df_phase1, aes(x=\"x\", y=\"y\", color=\"point_type\", group=\"sample\"))+\n",
        "  geom_point()+\n",
        "  geom_line(color=\"darkred\")+\n",
        "  scale_y_reverse()+\n",
        "  scale_color_manual(values=[\"darkred\", \"gray\"])+\n",
        "  theme_void() +\n",
        " labs(title=f\"Subject: {max_diff_row_subject_id} (Calibrated with phase 1 points)\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa-n8bXLt_H8"
      },
      "outputs": [],
      "source": [
        "v_predictions_phase2 = full_model.predict(test_ds_phase2_cal.skip(max_diff_row_idx).take(1).batch(1))[0]\n",
        "\n",
        "v_pts_phase2 = []\n",
        "\n",
        "for e in test_ds_phase2_cal.skip(max_diff_row_idx).take(1).as_numpy_iterator():\n",
        "  v_pts_phase2 = e[1]\n",
        "\n",
        "v_errors_phase2 = np.linalg.norm(v_predictions_phase2 - v_pts_phase2, axis=1)\n",
        "\n",
        "dfA_phase2 = pd.DataFrame({\"sample\": range(len(v_pts_phase2)), \"x\": v_pts_phase2[:,0], \"y\": v_pts_phase2[:,1], \"error\": v_errors_phase2, \"point_type\": \"target\"})\n",
        "dfB_phase2 = pd.DataFrame({\"sample\": range(len(v_pts_phase2)), \"x\": v_predictions_phase2[:,0], \"y\": v_predictions_phase2[:,1], \"error\": v_errors_phase2, \"point_type\": \"prediction\"})\n",
        "\n",
        "v_df_phase2 = pd.concat([dfA_phase2,dfB_phase2])\n",
        "\n",
        "(ggplot(v_df_phase2, aes(x=\"x\", y=\"y\", color=\"point_type\", group=\"sample\"))+\n",
        "  geom_point()+\n",
        "  geom_line(color=\"darkred\")+\n",
        "  scale_y_reverse()+\n",
        "  scale_color_manual(values=[\"darkred\", \"gray\"])+\n",
        "  theme_void() +\n",
        "  labs(title=f\"Subject: {max_diff_row_subject_id} (Calibrated with phase 2 points)\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization for eye images for different loss ranges"
      ],
      "metadata": {
        "id": "BrleMxzTw-E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_subj_loss_phase1_loss_5 = val_subj_loss_phase1[(val_subj_loss_phase1['loss'] >= 4) & (val_subj_loss_phase1['loss'] <= 6)].reset_index()\n",
        "\n",
        "val_subj_loss_phase1_loss_15 = val_subj_loss_phase1[(val_subj_loss_phase1['loss'] >= 14) & (val_subj_loss_phase1['loss'] <= 16)].reset_index()\n",
        "\n",
        "val_subj_loss_phase1_loss_20 = val_subj_loss_phase1[(val_subj_loss_phase1['loss'] >= 19) & (val_subj_loss_phase1['loss'] <= 21)].reset_index()"
      ],
      "metadata": {
        "id": "3gWJ7BaJAURw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_subj_loss_phase2_loss_5 = val_subj_loss_phase2[(val_subj_loss_phase2['loss'] >= 4) & (val_subj_loss_phase2['loss'] <= 6)].reset_index()\n",
        "\n",
        "val_subj_loss_phase2_loss_15 = val_subj_loss_phase2[(val_subj_loss_phase2['loss'] >= 14) & (val_subj_loss_phase2['loss'] <= 16)].reset_index()\n",
        "\n",
        "val_subj_loss_phase2_loss_20 = val_subj_loss_phase2[(val_subj_loss_phase2['loss'] >= 19) & (val_subj_loss_phase2['loss'] <= 21)].reset_index()"
      ],
      "metadata": {
        "id": "KO_j-sJULsDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_row_loss_5_idx = val_subj_loss_phase1_loss_5.loc[0]['index'].astype(int)\n",
        "rand_row_loss_15_idx = val_subj_loss_phase1_loss_15.loc[0]['index'].astype(int)\n",
        "rand_row_loss_20_idx = val_subj_loss_phase1_loss_20.loc[0]['index'].astype(int)"
      ],
      "metadata": {
        "id": "qFbt7D_yAtTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython.display import HTML\n",
        "import base64\n",
        "\n",
        "def visualize_eye_tracking_data(dataset, interval=100, figsize=(10, 6)):\n",
        "    # Extract data from the dataset\n",
        "    for inputs, labels, _ in dataset.take(1):\n",
        "        images = inputs[\"Input_All_Images\"]\n",
        "        coords = inputs[\"Input_All_Coords\"]\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        valid_images = images.numpy()\n",
        "        valid_coords = coords.numpy()\n",
        "\n",
        "        # Sort by X coordinate, then by Y coordinate\n",
        "        sorted_indices = np.lexsort((valid_coords[:, 0], valid_coords[:, 1]))\n",
        "        valid_images = valid_images[sorted_indices]\n",
        "        valid_coords = valid_coords[sorted_indices]\n",
        "\n",
        "        num_images = valid_images.shape[0]\n",
        "\n",
        "    # Set up the figure\n",
        "    plt.ioff()  # Turn off interactive mode to avoid displaying during generation\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    # Create a function that draws each frame\n",
        "    def draw_frame(frame_num):\n",
        "        ax.clear()\n",
        "\n",
        "        # Set up the 16:9 coordinate space\n",
        "        ax.set_xlim(0, 100)\n",
        "        ax.set_ylim(100, 0)  # 16:9 aspect ratio\n",
        "\n",
        "        # Get the current image and coordinates\n",
        "        img = valid_images[frame_num].squeeze()\n",
        "        x, y = valid_coords[frame_num]\n",
        "\n",
        "        # Draw rectangle for the screen\n",
        "        rect = plt.Rectangle((0, 0), 100, 100, fill=False, color='black', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        # Add image display in the top right corner\n",
        "        img_display = ax.inset_axes([0.35, 0.35, 0.3, 0.3], transform=ax.transAxes)\n",
        "        img_display.imshow(np.fliplr(img), cmap='gray')\n",
        "        img_display.axis('off')\n",
        "\n",
        "        # Draw red dot at the coordinate - make it bigger for visibility\n",
        "        ax.scatter(x * 100, y * 100, color='red', s=150, zorder=5,\n",
        "                  edgecolor='white', linewidth=1.5)\n",
        "\n",
        "        # Draw crosshair\n",
        "        ax.axhline(y * 100, color='gray', linestyle='--', alpha=0.5, zorder=1)\n",
        "        ax.axvline(x * 100, color='gray', linestyle='--', alpha=0.5, zorder=1)\n",
        "\n",
        "        # Set title\n",
        "        ax.set_title('Eye Tracking Visualization')\n",
        "\n",
        "        # Set axis labels\n",
        "        ax.set_xlabel('X Coordinate')\n",
        "        ax.set_ylabel('Y Coordinate')\n",
        "\n",
        "    # Create the animation\n",
        "    anim = animation.FuncAnimation(fig, draw_frame, frames=num_images, interval=interval)\n",
        "\n",
        "  # Use animation's to_jshtml method which directly generates HTML\n",
        "    html_animation = anim.to_jshtml()\n",
        "\n",
        "    # Clean up\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Create an HTML object that can be displayed in the notebook\n",
        "    return HTML(html_animation)"
      ],
      "metadata": {
        "id": "gd9YAdo5w9O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss in range 4-6 example visualization"
      ],
      "metadata": {
        "id": "vsdKCetqHQLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_eye_tracking_data_loss_5 = visualize_eye_tracking_data(test_ds_phase1_cal.skip(rand_row_loss_5_idx).take(1))\n",
        "visualize_eye_tracking_data_loss_5"
      ],
      "metadata": {
        "id": "CCP0EOus0nHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss in range 14-16 example visualization"
      ],
      "metadata": {
        "id": "0h587yHJHUTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_eye_tracking_data_loss_15 = visualize_eye_tracking_data(test_ds_phase1_cal.skip(rand_row_loss_15_idx).take(1))\n",
        "visualize_eye_tracking_data_loss_15"
      ],
      "metadata": {
        "id": "v-3-2ZM8C80J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss in range 19-20 example visualization"
      ],
      "metadata": {
        "id": "MLqrctywHW7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_eye_tracking_data_loss_20 = visualize_eye_tracking_data(test_ds_phase1_cal.skip(rand_row_loss_20_idx).take(1))\n",
        "visualize_eye_tracking_data_loss_20"
      ],
      "metadata": {
        "id": "JLoJjGFWC9Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase 1 max diff subject eye images visualization"
      ],
      "metadata": {
        "id": "-lm-dbwCHeL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_eye_tracking_data_max_diff_subject_phase1 = visualize_eye_tracking_data(test_ds_phase1_cal.skip(max_diff_row_idx).take(1))\n",
        "visualize_eye_tracking_data_max_diff_subject_phase1"
      ],
      "metadata": {
        "id": "136-RjBKHhJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase 2 ex_subject_id visualization"
      ],
      "metadata": {
        "id": "O_2JUhZHHov9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ARE THEY THE EXACT SAME VIDEO?????\n",
        "visualize_eye_tracking_data_max_diff_subject_phase2 = visualize_eye_tracking_data(test_ds_phase2_cal.skip(max_diff_row_idx).take(1))\n",
        "visualize_eye_tracking_data_max_diff_subject_phase2"
      ],
      "metadata": {
        "id": "EbwXSveEHov-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLWqn8aV-JiV"
      },
      "source": [
        "# Effect of number of calibration points on model performance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!osf -p th7fv fetch  model_losses_across_cal_configs_df.csv"
      ],
      "metadata": {
        "id": "ze4dA6gEWCiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7564478-8a51-45d4-c280-f52a000f8d19"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 6.01M/6.01M [00:01<00:00, 3.59Mbytes/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calibration points"
      ],
      "metadata": {
        "id": "LkiPnxE_HA2n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "h4MgPOmF-sMe"
      },
      "outputs": [],
      "source": [
        "cols = [5, 11, 17, 23, 29, 35, 41, 47, 53, 59, 65, 71, 77, 83, 89, 95]\n",
        "rows = [5, 16.25, 27.5, 38.75, 50, 61.25, 72.5, 83.75, 95]\n",
        "\n",
        "cal_cols = [5, 35, 65, 95]\n",
        "cal_rows = [5, 27.5, 50, 72.5, 95]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_points = [[a, b] for a in cols for b in rows]\n",
        "cal_points = [[c, d] for c in cal_cols for d in cal_rows]"
      ],
      "metadata": {
        "id": "_5Tgm2ccx8S4"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "2-4wGeWpoTFJ"
      },
      "outputs": [],
      "source": [
        "cols_cols_indices = [\n",
        "    [0,15],\n",
        "    [0,7,15],\n",
        "    [0,5,10,15],\n",
        "    [0,4,8,12,15],\n",
        "    [0,3,6,9,12,15],\n",
        "    [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "]\n",
        "\n",
        "rows_rows_indices = [\n",
        "    [0,8],\n",
        "    [0,4,8],\n",
        "    [0,2,4,6,8],\n",
        "    [0,1,2,3,4,5,6,7,8]\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RFwAAmeJpBk0"
      },
      "outputs": [],
      "source": [
        "cols_rows_indices = [\n",
        "    [tf.constant([cols[x],rows[y]], dtype=tf.float32)\n",
        "    for x in cols_indices for y in rows_indices]\n",
        "    for cols_indices in cols_cols_indices for rows_indices in rows_rows_indices\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_rows_indices = sorted(cols_rows_indices, key=lambda x: len(x))\n",
        "for i, config in enumerate(cols_rows_indices):\n",
        "  if i > 0 and len(config) == len(cols_rows_indices[i-1]):\n",
        "    cols_rows_indices.pop(i)"
      ],
      "metadata": {
        "id": "vXZCnmZOSr_Z"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "zaBN0liGrPvq"
      },
      "outputs": [],
      "source": [
        "cols_rows_indices_scaled = [tf.divide(config, tf.constant([100.])) for config in cols_rows_indices]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(zip(*all_points)))"
      ],
      "metadata": {
        "id": "oeJS-6yWyUPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d9d227-9a56-4b47-8310-0afeb6818807"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "5y6AtvOFYH8W"
      },
      "outputs": [],
      "source": [
        "def visualize_points(points):\n",
        "  plt.figure(figsize=(16, 9))\n",
        "  x_coords, y_coords = list(zip(*points))\n",
        "  x_all, y_all = list(zip(*all_points))\n",
        "  plt.scatter(x_all, y_all, alpha=0.3)\n",
        "  plt.scatter(x_coords, y_coords, c='black')\n",
        "\n",
        "  # Set x and y ticks to be the rows and cols\n",
        "  plt.xticks(cols)\n",
        "  plt.yticks(rows)\n",
        "  plt.xlabel(\"% of screen width\", fontsize=16)\n",
        "  plt.ylabel(\"% of screen height\", fontsize=16)\n",
        "  plt.title(\"Calibration Points\", fontsize=20)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_points(cal_points)"
      ],
      "metadata": {
        "id": "4CIA6Xitxs8H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1e091f0c-0876-4d8f-e81a-2c87da07788d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x900 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter function for subjects missing calibration points"
      ],
      "metadata": {
        "id": "oSwu9LpkNBjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_by_n_cal_points(features, labels, subject_ids, cal_points):\n",
        "  n_cal_points = len(cal_points)\n",
        "  images, coords, cal_mask, target_mask = features\n",
        "\n",
        "  return tf.equal(tf.reduce_sum(cal_mask, axis=-1), n_cal_points)\n"
      ],
      "metadata": {
        "id": "jkfsNDKyKwJ6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1 boxplot across \\# cal points"
      ],
      "metadata": {
        "id": "bu0RsNH8HCn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_losses_across_cal_phase1 = []\n",
        "for i, cal_config in enumerate(cols_rows_indices_scaled):\n",
        "  # Make masked dataset with the cal_config\n",
        "  masked_dataset_phase1_cal_config = prepare_masked_dataset(test_data_rescaled, cal_config, 1)\n",
        "\n",
        "  masked_dataset_phase1_cal_config_filtered = masked_dataset_phase1_cal_config.filter(\n",
        "      lambda features, labels, subject_ids: filter_by_n_cal_points(\n",
        "          features, labels, subject_ids, cal_config)\n",
        "  )\n",
        "\n",
        "  test_ds_phase1_cal_config = masked_dataset_phase1_cal_config_filtered.map(\n",
        "      prepare_model_inputs,\n",
        "      num_parallel_calls=tf.data.AUTOTUNE\n",
        "  ).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  # Get predictions\n",
        "  predictions_phase1_cal_config = full_model.predict(test_ds_phase1_cal_config.batch(BATCH_SIZE))\n",
        "\n",
        "  batch_losses_phase1_cal_config = []\n",
        "\n",
        "  for pred_batch, ds_batch in zip(predictions_phase1_cal_config, test_ds_phase1_cal_config.batch(1).as_numpy_iterator()):\n",
        "      y_true = ds_batch[1]\n",
        "      mask = ds_batch[0]['Input_Target_Mask'].reshape(-1)\n",
        "\n",
        "      batch_point_losses = normalized_weighted_euc_dist(y_true, pred_batch).numpy().reshape(-1)\n",
        "      batch_point_losses = batch_point_losses[mask == 1]\n",
        "\n",
        "      batch_losses_phase1_cal_config.append(batch_point_losses)\n",
        "  batch_losses_across_cal_phase1.append((cal_config, batch_losses_phase1_cal_config))"
      ],
      "metadata": {
        "id": "iLEWktF8B8cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cal_points_phase1 = [len(cal_config) for cal_config, _ in batch_losses_across_cal_phase1]\n",
        "# [len=19 array of\n",
        "    #[len=146 array of\n",
        "        # [len=144 array of losses\n",
        "        # for each point]\n",
        "    # for each subject]\n",
        "# for each cal_config]\n",
        "model_losses_phase1 = [batch_losses for _, batch_losses in batch_losses_across_cal_phase1]"
      ],
      "metadata": {
        "id": "uoHmXeE6Xz2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_data_phase1 = []\n",
        "for i, cal_config in enumerate(model_losses):  # Iterate through 19 cal_configs\n",
        "  for j, subject_model_losses in enumerate(cal_config): # Iterate through 146 subjects\n",
        "      img_count = np.count_nonzero(~np.isnan(subject_model_losses))\n",
        "      row = {\n",
        "          'num_cal_points': num_cal_points[i],\n",
        "          'subject_id': j,\n",
        "          'img_count': img_count,\n",
        "          'subj_mean_loss': np.mean(subject_model_losses)}\n",
        "      row.update({'point_' + str(k) + '_loss': val for k, val in enumerate(subject_model_losses)})\n",
        "      model_losses_df_data_phase1.append(row)\n",
        "\n",
        "model_losses_df_phase1 = pd.DataFrame(model_losses_df_phase1_data)\n",
        "model_losses_df_phase1 = model_losses_df_phase1.sort_values(by=['num_cal_points', 'subject_id'])"
      ],
      "metadata": {
        "id": "nnj444Zs4Qhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase1"
      ],
      "metadata": {
        "id": "5ue0zUYn93vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase1.to_csv('model_losses_across_cal_configs_phase1_df.csv')"
      ],
      "metadata": {
        "id": "UttnzKQ0xrPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_sorted_phase1 = model_losses_df_phase1.sort_values(by='num_cal_points')\n",
        "\n",
        "ordered_cal_points_phase1 = sorted(model_losses_df_phase1['num_cal_points'].unique())\n",
        "ordered_cal_points_str_phase1 = [str(x) for x in ordered_cal_points_phase1]\n",
        "\n",
        "model_losses_df_sorted_phase1['num_cal_points_cat'] = pd.Categorical(\n",
        "    model_losses_df_sorted_phase1['num_cal_points'].astype(str),\n",
        "    categories=ordered_cal_points_str_phase1,\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "model_losses_across_cal_configs_phase1_boxplot = (\n",
        "    ggplot(model_losses_df_sorted_phase1, aes(x='num_cal_points_cat', y='subj_mean_loss'))\n",
        "    + geom_boxplot()\n",
        "    + labs(\n",
        "        title=\"Model Error Across Number of Calibration Points\",\n",
        "        x=\"#Calibration points\",\n",
        "        y=\"Model error\"\n",
        "    )\n",
        "    + theme_classic()\n",
        "    + theme(\n",
        "        plot_title=element_text(hjust=0.5),\n",
        "        axis_text_x=element_text(angle=45, hjust=1)\n",
        "    )\n",
        ")\n",
        "\n",
        "model_losses_across_cal_configs_phase1_boxplot"
      ],
      "metadata": {
        "id": "qY6SfYzT8weB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2 boxplot across \\# cal points"
      ],
      "metadata": {
        "id": "dtsSj-j9ajrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_losses_across_cal_phase2 = []\n",
        "for i, cal_config in enumerate(cols_rows_indices_scaled):\n",
        "  # Make masked dataset with the cal_config\n",
        "  masked_dataset_phase2_cal_config = prepare_masked_dataset(test_data_rescaled, cal_config, 2)\n",
        "\n",
        "  masked_dataset_phase2_cal_config_filtered = masked_dataset_phase2_cal_config.filter(\n",
        "      lambda features, labels, subject_ids: filter_by_n_cal_points(\n",
        "          features, labels, subject_ids, cal_config)\n",
        "  )\n",
        "\n",
        "  test_ds_phase2_cal_config = masked_dataset_phase2_cal_config_filtered.map(\n",
        "      prepare_model_inputs,\n",
        "      num_parallel_calls=tf.data.AUTOTUNE\n",
        "  ).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  # Get predictions\n",
        "  predictions_phase2_cal_config = full_model.predict(test_ds_phase2_cal_config.batch(BATCH_SIZE))\n",
        "\n",
        "  batch_losses_phase2_cal_config = []\n",
        "\n",
        "  for pred_batch, ds_batch in zip(predictions_phase2_cal_config, test_ds_phase2_cal_config.batch(1).as_numpy_iterator()):\n",
        "      y_true = ds_batch[1]\n",
        "      mask = ds_batch[0]['Input_Target_Mask'].reshape(-1)\n",
        "\n",
        "      batch_point_losses = normalized_weighted_euc_dist(y_true, pred_batch).numpy().reshape(-1)\n",
        "      batch_point_losses = batch_point_losses[mask == 1]\n",
        "\n",
        "      batch_losses_phase2_cal_config.append(batch_point_losses)\n",
        "  batch_losses_across_cal_phase2.append((cal_config, batch_losses_phase2_cal_config))"
      ],
      "metadata": {
        "id": "Ne_oVk0MajrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbdab15c-be38-4fdc-aa45-53d831047f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 10s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 10s/step\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 10s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 11s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 10s/step\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 10s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 10s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 10s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 11s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 13s/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 10s/step\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 10s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 10s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 10s/step\n",
            "     21/Unknown \u001b[1m271s\u001b[0m 13s/step"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cal_points_phase2 = [len(cal_config) for cal_config, _ in batch_losses_across_cal_phase2]\n",
        "model_losses_phase2 = [batch_losses for _, batch_losses in batch_losses_across_cal_phase2]"
      ],
      "metadata": {
        "id": "kjUXS91EajrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_data_phase2 = []\n",
        "for i, cal_config in enumerate(model_losses_phase2):  # Iterate through 19 cal_configs\n",
        "  for j, subject_model_losses in enumerate(cal_config): # Iterate through 146 subjects\n",
        "      img_count = np.count_nonzero(~np.isnan(subject_model_losses))\n",
        "      row = {\n",
        "          'num_cal_points': num_cal_points_phase2[i],\n",
        "          'subject_id': j,\n",
        "          'img_count': img_count,\n",
        "          'subj_mean_loss': np.mean(subject_model_losses)}\n",
        "      row.update({'point_' + str(k) + '_loss': val for k, val in enumerate(subject_model_losses)})\n",
        "      model_losses_df_data_phase2.append(row)\n",
        "\n",
        "model_losses_df_phase2 = pd.DataFrame(model_losses_df_data_phase2)\n",
        "model_losses_df_phase2 = model_losses_df_phase2.sort_values(by=['num_cal_points', 'subject_id'])"
      ],
      "metadata": {
        "id": "ZTikdCbUajrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase2"
      ],
      "metadata": {
        "id": "ultZI6HIajrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase2.to_csv('model_losses_across_cal_configs_phase2_df.csv')"
      ],
      "metadata": {
        "id": "NKBWHsa1ajrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_sorted_phase2 = model_losses_df_phase2.sort_values(by='num_cal_points')\n",
        "\n",
        "ordered_cal_points_phase2 = sorted(model_losses_df_phase2['num_cal_points'].unique())\n",
        "ordered_cal_points_str_phase2 = [str(x) for x in ordered_cal_points_phase2]\n",
        "\n",
        "model_losses_df_sorted_phase2['num_cal_points_cat'] = pd.Categorical(\n",
        "    model_losses_df_sorted_phase2['num_cal_points'].astype(str),\n",
        "    categories=ordered_cal_points_str_phase2,\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "model_losses_across_cal_configs_phase2_boxplot = (\n",
        "    ggplot(model_losses_df_sorted_phase2, aes(x='num_cal_points_cat', y='subj_mean_loss'))\n",
        "    + geom_boxplot()\n",
        "    + labs(\n",
        "        title=\"Model Error Across Number of Calibration Points\",\n",
        "        x=\"#Calibration points\",\n",
        "        y=\"Model error\"\n",
        "    )\n",
        "    + theme_classic()\n",
        "    + theme(\n",
        "        plot_title=element_text(hjust=0.5),\n",
        "        axis_text_x=element_text(angle=45, hjust=1)\n",
        "    )\n",
        ")\n",
        "\n",
        "model_losses_across_cal_configs_phase2_boxplot"
      ],
      "metadata": {
        "id": "YdyCpN-sajrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1+2 boxplot across \\# cal points"
      ],
      "metadata": {
        "id": "QxJPp53BD0NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_losses_across_cal_phase_both = []\n",
        "for i, cal_config in enumerate(cols_rows_indices_scaled):\n",
        "  # Make masked dataset with the cal_config\n",
        "  masked_dataset_phase_both_cal_config = prepare_masked_dataset(test_data_rescaled, cal_config)\n",
        "\n",
        "  masked_dataset_phase_both_cal_config_filtered = masked_dataset_phase_both_cal_config.filter(\n",
        "      lambda features, labels, subject_ids: filter_by_n_cal_points(\n",
        "          features, labels, subject_ids, cal_config)\n",
        "  )\n",
        "\n",
        "  test_ds_phase_both_cal_config = masked_dataset_phase_both_cal_config_filtered.map(\n",
        "      prepare_model_inputs,\n",
        "      num_parallel_calls=tf.data.AUTOTUNE\n",
        "  ).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  # Get predictions\n",
        "  predictions_phase_both_cal_config = full_model.predict(test_ds_phase_both_cal_config.batch(BATCH_SIZE))\n",
        "\n",
        "  batch_losses_phase_both_cal_config = []\n",
        "\n",
        "  for pred_batch, ds_batch in zip(predictions_phase_both_cal_config, test_ds_phase_both_cal_config.batch(1).as_numpy_iterator()):\n",
        "      y_true = ds_batch[1]\n",
        "      mask = ds_batch[0]['Input_Target_Mask'].reshape(-1)\n",
        "\n",
        "      batch_point_losses = normalized_weighted_euc_dist(y_true, pred_batch).numpy().reshape(-1)\n",
        "      batch_point_losses = batch_point_losses[mask == 1]\n",
        "\n",
        "      batch_losses_phase_both_cal_config.append(batch_point_losses)\n",
        "  batch_losses_across_cal_phase_both.append((cal_config, batch_losses_phase_both_cal_config))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbdab15c-be38-4fdc-aa45-53d831047f40",
        "id": "ANabWGVlD0NN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 10s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 10s/step\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 10s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 11s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 10s/step\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 10s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 10s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 10s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 11s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 13s/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 10s/step\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 10s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 10s/step\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 10s/step\n",
            "      8/Unknown \u001b[1m85s\u001b[0m 10s/step"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cal_points_phase_both = [len(cal_config) for cal_config, _ in batch_losses_across_cal_phase_both]\n",
        "model_losses_phase_both = [batch_losses for _, batch_losses in batch_losses_across_cal_phase_both]"
      ],
      "metadata": {
        "id": "G3OH9EN6D0NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_data_phase_both = []\n",
        "for i, cal_config in enumerate(model_losses_phase_both):  # Iterate through 19 cal_configs\n",
        "  for j, subject_model_losses in enumerate(cal_config): # Iterate through 146 subjects\n",
        "      img_count = np.count_nonzero(~np.isnan(subject_model_losses))\n",
        "      row = {\n",
        "          'num_cal_points': num_cal_points_phase_both[i],\n",
        "          'subject_id': j,\n",
        "          'img_count': img_count,\n",
        "          'subj_mean_loss': np.mean(subject_model_losses)}\n",
        "      row.update({'point_' + str(k) + '_loss': val for k, val in enumerate(subject_model_losses)})\n",
        "      model_losses_df_data_phase_both.append(row)\n",
        "\n",
        "model_losses_df_phase_both = pd.DataFrame(model_losses_df_data_phase_both)\n",
        "model_losses_df_phase_both = model_losses_df_phase_both.sort_values(by=['num_cal_points', 'subject_id'])"
      ],
      "metadata": {
        "id": "K6C0Ht2CD0NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase_both"
      ],
      "metadata": {
        "id": "IqTiRBY8D0NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase_both.to_csv('model_losses_across_cal_configs_phase_both_df.csv')"
      ],
      "metadata": {
        "id": "SIypK6VSD0NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_sorted_phase_both = model_losses_df_phase_both.sort_values(by='num_cal_points')\n",
        "\n",
        "ordered_cal_points_phase_both = sorted(model_losses_df_phase_both['num_cal_points'].unique())\n",
        "ordered_cal_points_str_phase_both = [str(x) for x in ordered_cal_points_phase_both]\n",
        "\n",
        "model_losses_df_sorted_phase_both['num_cal_points_cat'] = pd.Categorical(\n",
        "    model_losses_df_sorted_phase_both['num_cal_points'].astype(str),\n",
        "    categories=ordered_cal_points_str_phase_both,\n",
        "    ordered=True\n",
        ")\n",
        "\n",
        "model_losses_across_cal_configs_phase_both_boxplot = (\n",
        "    ggplot(model_losses_df_sorted_phase_both, aes(x='num_cal_points_cat', y='subj_mean_loss'))\n",
        "    + geom_boxplot()\n",
        "    + labs(\n",
        "        title=\"Model Error Across Number of Calibration Points\",\n",
        "        x=\"#Calibration points\",\n",
        "        y=\"Model error\"\n",
        "    )\n",
        "    + theme_classic()\n",
        "    + theme(\n",
        "        plot_title=element_text(hjust=0.5),\n",
        "        axis_text_x=element_text(angle=45, hjust=1)\n",
        "    )\n",
        ")\n",
        "\n",
        "model_losses_across_cal_configs_phase_both_boxplot"
      ],
      "metadata": {
        "id": "5LrVWr_ED0NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1 ribbon plot across \\# cal points"
      ],
      "metadata": {
        "id": "lrrJTcdcFpcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase1['mean_loss'] = model_losses_df_phase1.groupby('num_cal_points')['subj_mean_loss'].transform('mean')\n",
        "model_losses_df_phase1['median_loss'] = model_losses_df_phase1.groupby('num_cal_points')['subj_mean_loss'].transform('median')\n",
        "model_losses_df_phase1['min_loss'] = model_losses_df_phase1.groupby('num_cal_points')['subj_mean_loss'].transform('min')\n",
        "model_losses_df_phase1['max_loss'] = model_losses_df_phase1.groupby('num_cal_points')['subj_mean_loss'].transform('max')"
      ],
      "metadata": {
        "id": "orSdq8FEuUFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase1['2_50 loss'] = model_losses_df_phase1.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 2.5))\n",
        "model_losses_df_phase1['12_5 loss'] = model_losses_df_phase1.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 12.5))\n",
        "model_losses_df_phase1['25_0 loss'] = model_losses_df_phase1.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 25))\n",
        "model_losses_df_phase1['75_0 loss'] = model_losses_df_phase1.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 75))\n",
        "model_losses_df_phase1['87_5 loss'] = model_losses_df_phase1.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 87.5))\n",
        "model_losses_df_phase1['97_5 loss'] = model_losses_df_phase1.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 97.5))"
      ],
      "metadata": {
        "id": "5yNBe53Uwr9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase1"
      ],
      "metadata": {
        "id": "U2IOa72fA1PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ribbon_map = {'2.5% to 97.5%': '#b8f7ff', '12.5% to 87.5%': '#8dc1fc', '25% to 75%': '#5d68de'}\n",
        "\n",
        "model_losses_across_cal_configs_ribbon_plot_phase1 = (\n",
        "    ggplot(model_losses_df_phase1, aes(x='num_cal_points')) +\n",
        "    geom_ribbon(aes(ymin='2_50 loss', ymax='97_5 loss', fill='\"2.5% to 97.5%\"'), alpha=0.6) +\n",
        "    geom_ribbon(aes(ymin='12_5 loss', ymax='87_5 loss', fill='\"12.5% to 87.5%\"'), alpha=0.6) +\n",
        "    geom_ribbon(aes(ymin='25_0 loss', ymax='75_0 loss', fill='\"25% to 75%\"'), alpha=0.6) +\n",
        "    geom_line(aes(y='median_loss'), color='#333', size=1) +\n",
        "    geom_point(aes(y='median_loss'), size=1, alpha=0.05, color='#333') +\n",
        "    geom_point(aes(x='num_cal_points', y='min_loss'), size=0.5, alpha=0.05) +\n",
        "    geom_point(aes(x='num_cal_points', y='max_loss'), size=0.5, alpha=0.05) +\n",
        "    scale_x_continuous(breaks=(4,8,15,20,25,30,36,45,54,80,144), limits=(None, 144)) +\n",
        "    scale_fill_manual(\n",
        "        name=\"% of subjects\",\n",
        "        values=ribbon_map\n",
        "    ) +\n",
        "    labs(\n",
        "        x='#Calibration Points',\n",
        "        y='Model loss',\n",
        "        title='Loss Distribution across different #calibration points (Phase 1)'\n",
        "    ) +\n",
        "    theme(\n",
        "        panel_grid=element_blank(),\n",
        "        panel_background=element_blank(),\n",
        "        plot_background=element_blank(),\n",
        "        axis_line=element_line(color='black', size=1),\n",
        "        axis_text_x=element_text(hjust=1),\n",
        "        axis_title=element_text(),\n",
        "        plot_title=element_text(),\n",
        "        legend_title=element_text(size=10),\n",
        "        legend_text=element_text(size=8),\n",
        "        legend_position=\"bottom\"\n",
        "    )\n",
        ")\n",
        "\n",
        "model_losses_across_cal_configs_ribbon_plot_phase1"
      ],
      "metadata": {
        "id": "wo67Eu3ctEsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2 ribbon plot across \\# cal points"
      ],
      "metadata": {
        "id": "tbf5NtoTb0fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase2['mean_loss'] = model_losses_df_phase2.groupby('num_cal_points')['subj_mean_loss'].transform('mean')\n",
        "model_losses_df_phase2['median_loss'] = model_losses_df_phase2.groupby('num_cal_points')['subj_mean_loss'].transform('median')\n",
        "model_losses_df_phase2['min_loss'] = model_losses_df_phase2.groupby('num_cal_points')['subj_mean_loss'].transform('min')\n",
        "model_losses_df_phase2['max_loss'] = model_losses_df_phase2.groupby('num_cal_points')['subj_mean_loss'].transform('max')"
      ],
      "metadata": {
        "id": "hsqMXy23b0fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase2['2_50 loss'] = model_losses_df_phase2.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 2.5))\n",
        "model_losses_df_phase2['12_5 loss'] = model_losses_df_phase2.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 12.5))\n",
        "model_losses_df_phase2['25_0 loss'] = model_losses_df_phase2.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 25))\n",
        "model_losses_df_phase2['75_0 loss'] = model_losses_df_phase2.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 75))\n",
        "model_losses_df_phase2['87_5 loss'] = model_losses_df_phase2.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 87.5))\n",
        "model_losses_df_phase2['97_5 loss'] = model_losses_df_phase2.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 97.5))"
      ],
      "metadata": {
        "id": "Tk-jWOQub0fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase2"
      ],
      "metadata": {
        "id": "R5TXI0Tab0fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ribbon_map = {'2.5% to 97.5%': '#b8f7ff', '12.5% to 87.5%': '#8dc1fc', '25% to 75%': '#5d68de'}\n",
        "\n",
        "model_losses_across_cal_configs_ribbon_plot_phase2 = (\n",
        "    ggplot(model_losses_df_phase2, aes(x='num_cal_points')) +\n",
        "    geom_ribbon(aes(ymin='2_50 loss', ymax='97_5 loss', fill='\"2.5% to 97.5%\"'), alpha=0.6) +\n",
        "    geom_ribbon(aes(ymin='12_5 loss', ymax='87_5 loss', fill='\"12.5% to 87.5%\"'), alpha=0.6) +\n",
        "    geom_ribbon(aes(ymin='25_0 loss', ymax='75_0 loss', fill='\"25% to 75%\"'), alpha=0.6) +\n",
        "    geom_line(aes(y='median_loss'), color='#333', size=1) +\n",
        "    geom_point(aes(y='median_loss'), size=1, alpha=0.05, color='#333') +\n",
        "    geom_point(aes(x='num_cal_points', y='min_loss'), size=0.5, alpha=0.05) +\n",
        "    geom_point(aes(x='num_cal_points', y='max_loss'), size=0.5, alpha=0.05) +\n",
        "    scale_x_continuous(breaks=(4,8,15,20,25,30,36,45,54,80,144), limits=(None, 144)) +\n",
        "    scale_fill_manual(\n",
        "        name=\"% of subjects\",\n",
        "        values=ribbon_map\n",
        "    ) +\n",
        "    labs(\n",
        "        x='#Calibration Points',\n",
        "        y='Model loss',\n",
        "        title='Loss Distribution across different #calibration points (Phase 2)'\n",
        "    ) +\n",
        "    theme(\n",
        "        panel_grid=element_blank(),\n",
        "        panel_background=element_blank(),\n",
        "        plot_background=element_blank(),\n",
        "        axis_line=element_line(color='black', size=1),\n",
        "        axis_text_x=element_text(hjust=1),\n",
        "        axis_title=element_text(),\n",
        "        plot_title=element_text(),\n",
        "        legend_title=element_text(size=10),\n",
        "        legend_text=element_text(size=8),\n",
        "        legend_position=\"bottom\"\n",
        "    )\n",
        ")\n",
        "\n",
        "model_losses_across_cal_configs_ribbon_plot_phase2"
      ],
      "metadata": {
        "id": "gyGvRxt1b0fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1+2 ribbon plot across \\# cal points"
      ],
      "metadata": {
        "id": "pPtI5f6uFuap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase_both['mean_loss'] = model_losses_df_phase_both.groupby('num_cal_points')['subj_mean_loss'].transform('mean')\n",
        "model_losses_df_phase_both['median_loss'] = model_losses_df_phase_both.groupby('num_cal_points')['subj_mean_loss'].transform('median')\n",
        "model_losses_df_phase_both['min_loss'] = model_losses_df_phase_both.groupby('num_cal_points')['subj_mean_loss'].transform('min')\n",
        "model_losses_df_phase_both['max_loss'] = model_losses_df_phase_both.groupby('num_cal_points')['subj_mean_loss'].transform('max')"
      ],
      "metadata": {
        "id": "A9uOHpZMFuaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase_both['2_50 loss'] = model_losses_df_phase_both.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 2.5))\n",
        "model_losses_df_phase_both['12_5 loss'] = model_losses_df_phase_both.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 12.5))\n",
        "model_losses_df_phase_both['25_0 loss'] = model_losses_df_phase_both.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 25))\n",
        "model_losses_df_phase_both['75_0 loss'] = model_losses_df_phase_both.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 75))\n",
        "model_losses_df_phase_both['87_5 loss'] = model_losses_df_phase_both.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 87.5))\n",
        "model_losses_df_phase_both['97_5 loss'] = model_losses_df_phase_both.groupby('num_cal_points')['subj_mean_loss'].transform(lambda x: np.percentile(x, 97.5))"
      ],
      "metadata": {
        "id": "8CaoFFpAFuar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses_df_phase_both"
      ],
      "metadata": {
        "id": "pS6LIXADFuar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ribbon_map = {'2.5% to 97.5%': '#b8f7ff', '12.5% to 87.5%': '#8dc1fc', '25% to 75%': '#5d68de'}\n",
        "\n",
        "model_losses_across_cal_configs_ribbon_plot_phase_both = (\n",
        "    ggplot(model_losses_df_phase_both, aes(x='num_cal_points')) +\n",
        "    geom_ribbon(aes(ymin='2_50 loss', ymax='97_5 loss', fill='\"2.5% to 97.5%\"'), alpha=0.6) +\n",
        "    geom_ribbon(aes(ymin='12_5 loss', ymax='87_5 loss', fill='\"12.5% to 87.5%\"'), alpha=0.6) +\n",
        "    geom_ribbon(aes(ymin='25_0 loss', ymax='75_0 loss', fill='\"25% to 75%\"'), alpha=0.6) +\n",
        "    geom_line(aes(y='median_loss'), color='#333', size=1) +\n",
        "    geom_point(aes(y='median_loss'), size=1, alpha=0.05, color='#333') +\n",
        "    geom_point(aes(x='num_cal_points', y='min_loss'), size=0.5, alpha=0.05) +\n",
        "    geom_point(aes(x='num_cal_points', y='max_loss'), size=0.5, alpha=0.05) +\n",
        "    scale_x_continuous(breaks=(4,8,15,20,25,30,36,45,54,80,144), limits=(None, 144)) +\n",
        "    scale_fill_manual(\n",
        "        name=\"% of subjects\",\n",
        "        values=ribbon_map\n",
        "    ) +\n",
        "    labs(\n",
        "        x='#Calibration Points',\n",
        "        y='Model loss',\n",
        "        title='Loss Distribution across different #calibration points (Phase 2)'\n",
        "    ) +\n",
        "    theme(\n",
        "        panel_grid=element_blank(),\n",
        "        panel_background=element_blank(),\n",
        "        plot_background=element_blank(),\n",
        "        axis_line=element_line(color='black', size=1),\n",
        "        axis_text_x=element_text(hjust=1),\n",
        "        axis_title=element_text(),\n",
        "        plot_title=element_text(),\n",
        "        legend_title=element_text(size=10),\n",
        "        legend_text=element_text(size=8),\n",
        "        legend_position=\"bottom\"\n",
        "    )\n",
        ")\n",
        "\n",
        "model_losses_across_cal_configs_ribbon_plot_phase_both"
      ],
      "metadata": {
        "id": "EFbcMyiIFuar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9k1pHkzWXtE"
      },
      "source": [
        "# Effect of glasses on model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Lid2QPQWbk_"
      },
      "outputs": [],
      "source": [
        "!osf -p uf2sh fetch glasses_info.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTsFHAl_vHfG"
      },
      "outputs": [],
      "source": [
        "glasses_df = pd.read_csv('glasses_info.csv')\n",
        "glasses_df['subject_b36'] = glasses_df['subject_id'].apply(lambda x: int(x, 36))\n",
        "glasses_df['wore_glasses'] = glasses_df['wore_glasses'].apply(lambda x: True if x == 'yes' else False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOn6XN6T4bhH"
      },
      "outputs": [],
      "source": [
        "losses_df = pd.DataFrame(columns=[\"subject_b36\", \"batch_loss\"])\n",
        "losses_df[\"subject_b36\"] = subject_ids\n",
        "losses_df['batch_loss'] = batch_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuvvpyOK5qrV"
      },
      "outputs": [],
      "source": [
        "validation_glasses_df = pd.merge(glasses_df, losses_df, on='subject_b36', how=\"inner\")\n",
        "validation_glasses_df = validation_glasses_df.drop(['subject_id'], axis=1)\n",
        "validation_glasses_only_df = validation_glasses_df[validation_glasses_df['wore_glasses'] == True]\n",
        "validation_no_glasses_df = validation_glasses_df[validation_glasses_df['wore_glasses'] == False]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_glasses_df"
      ],
      "metadata": {
        "id": "crcd-1hpI181"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TILTEIdJLI_O"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "n, bins, patches = plt.hist(\n",
        "    [validation_glasses_only_df['batch_loss'], validation_no_glasses_df['batch_loss']],\n",
        "    bins=np.arange(0.01,0.23, 0.01),\n",
        "    edgecolor='white',\n",
        "    label=['Wore glasses', 'Did not wear glasses'],\n",
        "    color=['#333', '#AAA'])\n",
        "plt.title('Effect of Wearing Glasses on Model Error')\n",
        "plt.xlabel('Avg. Error - Proportion of Screen Diagonal')\n",
        "plt.ylabel('# subjects')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spread out vs focused calibration"
      ],
      "metadata": {
        "id": "RlSR_8-4N1WC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "middle_cols = [29, 47, 53, 71]\n",
        "middle_rows = [27.5, 50, 72.5,]\n",
        "middle_cols_rows_indices = [tf.constant([x, y], dtype=tf.float32) for y in middle_rows for x in middle_cols]\n",
        "middle_cols_rows_indices_scaled = tf.divide(middle_cols_rows_indices, tf.constant([100.]))"
      ],
      "metadata": {
        "id": "XFcoMY2yN4xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## filter before running predictions"
      ],
      "metadata": {
        "id": "G0gob8OHu6q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "middle_cols_full = [29, 35, 41, 47, 53, 59, 65, 71]\n",
        "middle_rows_full = [27.5, 38.75, 50, 61.25, 72.5,]\n",
        "middle_cols_rows_indices_full = [tf.constant([x, y], dtype=tf.float32) for y in middle_rows_full for x in middle_cols_full]\n",
        "middle_cols_rows_indices_full_scaled = tf.divide(middle_cols_rows_indices_full, tf.constant([100.]))"
      ],
      "metadata": {
        "id": "m1GJOJk3j8X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def middle_filter_cal_points(image, mesh, coords, id):\n",
        "\n",
        "  return tf.reduce_any(tf.reduce_all(tf.equal(coords, middle_cols_rows_indices_full_scaled), axis=1))\n",
        "\n",
        "def middle_reducer_function_fixed_pts_with_id(subject_id, ds):\n",
        "\n",
        "  non_cal_points = ds.batch(144, drop_remainder=True).map(map_for_non_calibration_pts)\n",
        "\n",
        "  points = ds.filter(middle_filter_cal_points).batch(len(middle_cols_rows_indices_full)).map(map_for_calibration_pts).repeat()\n",
        "\n",
        "  merged = tf.data.Dataset.zip(points, non_cal_points)\n",
        "\n",
        "  return merged.map(lambda x, y: map_for_merged_with_id(x, y, subject_id))"
      ],
      "metadata": {
        "id": "lvhYDyUkjQZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## filter after running predictions"
      ],
      "metadata": {
        "id": "eAOupvvgvBVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cal_points = middle_cols_rows_indices\n",
        "scaled_cal_points = middle_cols_rows_indices_scaled\n",
        "v = validation_data_rescaled.group_by_window(\n",
        "    key_func = lambda img, m, c, z: z,\n",
        "    reduce_func = reducer_function_fixed_pts_with_id,\n",
        "    window_size = 200\n",
        ").cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "vT5I0qBqW9lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "middle_batch_losses = []\n",
        "middle_subject_ids = []\n",
        "middle_y_true = []\n",
        "filtered_y_true = []\n",
        "\n",
        "for e in v.batch(1).as_numpy_iterator():\n",
        "    middle_y_true.append(e[1])\n",
        "    middle_subject_ids.append(e[2][0])\n",
        "\n",
        "middle_y_true = np.array(middle_y_true).reshape(-1, 144, 2)\n",
        "middle_predictions = full_model.predict(v.batch(1))\n",
        "\n",
        "for i in range(len(middle_predictions)): # 153\n",
        "  loss = normalized_weighted_euc_dist(middle_y_true[i], middle_predictions[i]).numpy()\n",
        "  new_loss = []\n",
        "  new_y_true = []\n",
        "  for j, trial_loss in enumerate(loss): # 144\n",
        "    if (middle_y_true[i][j][0] > 0.25 and\n",
        "        middle_y_true[i][j][0] < 0.75 and\n",
        "        middle_y_true[i][j][1] > 0.17 and\n",
        "        middle_y_true[i][j][1] < 0.83):\n",
        "      new_loss.append(trial_loss)\n",
        "      new_y_true.append(middle_y_true[i][j])\n",
        "  filtered_y_true.append(new_y_true)\n",
        "  middle_batch_losses.append(new_loss)\n",
        "\n",
        "middle_batch_losses = np.array(middle_batch_losses)\n",
        "\n",
        "# Get mean per subject\n",
        "middle_batch_losses = np.mean(middle_batch_losses, axis=1)"
      ],
      "metadata": {
        "id": "98MNDpwHa-q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outer_cols = [5, 17, 29, 41, 59, 71, 83, 95]\n",
        "outer_rows = [5, 27.25, 50, 72.5, 95]\n",
        "outer_cols_rows_indices = [tf.constant([x, y], dtype=tf.float32) for y in outer_rows for x in outer_cols]\n",
        "outer_cols_rows_indices_scaled = tf.divide(outer_cols_rows_indices, tf.constant([100.]))"
      ],
      "metadata": {
        "id": "dtvXFGRUNPqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cal_points = outer_cols_rows_indices\n",
        "scaled_cal_points = outer_cols_rows_indices_scaled\n",
        "v = validation_data_rescaled.group_by_window(\n",
        "    key_func = lambda img, m, c, z: z,\n",
        "    reduce_func = reducer_function_fixed_pts_with_id,\n",
        "    window_size = 200\n",
        ").cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "apmzSWmNXJ8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outer_batch_losses = []\n",
        "outer_subject_ids = []\n",
        "outer_y_true = []\n",
        "filtered_y_true = []\n",
        "\n",
        "for e in v.batch(1).as_numpy_iterator():\n",
        "    outer_y_true.append(e[1])\n",
        "    outer_subject_ids.append(e[2][0])\n",
        "\n",
        "outer_y_true = np.array(outer_y_true).reshape(-1, 144, 2)\n",
        "outer_predictions = full_model.predict(v.batch(1))\n",
        "\n",
        "for i in range(len(outer_predictions)): # 153\n",
        "  loss = normalized_weighted_euc_dist(outer_y_true[i], outer_predictions[i]).numpy()\n",
        "  new_loss = []\n",
        "  new_y_true = []\n",
        "  for j, trial_loss in enumerate(loss): # 144\n",
        "    if (outer_y_true[i][j][0] > 0.25 and\n",
        "        outer_y_true[i][j][0] < 0.75 and\n",
        "        outer_y_true[i][j][1] > 0.17 and\n",
        "        outer_y_true[i][j][1] < 0.83):\n",
        "      new_loss.append(trial_loss)\n",
        "      new_y_true.append(outer_y_true[i][j])\n",
        "  filtered_y_true.append(new_y_true)\n",
        "  outer_batch_losses.append(new_loss)\n",
        "\n",
        "outer_batch_losses = np.array(outer_batch_losses)\n",
        "\n",
        "# Get mean per subject\n",
        "outer_batch_losses = np.mean(outer_batch_losses, axis=1)"
      ],
      "metadata": {
        "id": "Z7IZ6U2pO_8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "n, bins, patches = plt.hist(\n",
        "    [middle_batch_losses, outer_batch_losses],\n",
        "    bins=np.arange(0.01,0.23, 0.01),\n",
        "    color=['#333', '#AAA'],\n",
        "    edgecolor='white',\n",
        "    label=['Focused calibration', 'Spread out calibration'])\n",
        "plt.title('Focused vs. Spread out calibration')\n",
        "plt.xlabel('Avg. Error - Proportion of Screen Diagonal')\n",
        "plt.ylabel('# subjects')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RaIqHYh-PEhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Horizontal AOIs vs Vertical AOIs"
      ],
      "metadata": {
        "id": "OY6NQx9zN5d0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [5, 11, 17, 23, 29, 35, 41, 47, 53, 59, 65, 71, 77, 83, 89, 95]\n",
        "rows = [5, 16.25, 27.5, 38.75, 50, 61.25, 72.5, 83.75, 95]\n",
        "total_points = tf.constant([[col, row] for col in cols for row in rows], dtype=tf.float32)"
      ],
      "metadata": {
        "id": "AK0T-ivAe5Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cal_points = tf.constant([\n",
        "    [5, 5],\n",
        "    [5, 27.5],\n",
        "    [5, 50],\n",
        "    [5, 72.5],\n",
        "    [5, 95],\n",
        "    [35, 5],\n",
        "    [35, 27.5],\n",
        "    [35, 50],\n",
        "    [35, 72.5],\n",
        "    [35, 95],\n",
        "    [65, 5],\n",
        "    [65, 27.5],\n",
        "    [65, 50],\n",
        "    [65, 72.5],\n",
        "    [65, 95],\n",
        "    [95, 5],\n",
        "    [95, 27.5],\n",
        "    [95, 50],\n",
        "    [95, 72.5],\n",
        "    [95, 95],\n",
        "], dtype=tf.float32)\n",
        "\n",
        "scaled_cal_points = tf.divide(cal_points, tf.constant([100.]))"
      ],
      "metadata": {
        "id": "AyPwQj5gN7sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = validation_data_rescaled.group_by_window(\n",
        "    key_func = lambda img, m, c, z: z,\n",
        "    reduce_func = reducer_function_fixed_pts_with_id,\n",
        "    window_size = 200\n",
        ").cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "5Av6_ZcIFXiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store the batch losses\n",
        "subject_ids = []\n",
        "y_true = []\n",
        "\n",
        "for e in v.batch(1).as_numpy_iterator():\n",
        "\n",
        "    y_true.append(e[1])\n",
        "    subject_ids.append(e[2][0])\n",
        "\n",
        "y_true = np.array(y_true).reshape(-1, 144, 2)\n",
        "\n",
        "# this step is slower than expected. not sure what's going on.\n",
        "predictions = full_model.predict(v.batch(1))"
      ],
      "metadata": {
        "id": "y_K2bhsQOCuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_losses = []\n",
        "x_losses = []\n",
        "y_losses = []\n",
        "\n",
        "for i in range(len(predictions)): #153\n",
        "  loss = normalized_weighted_euc_dist(y_true[i], predictions[i]).numpy()\n",
        "  subject_x_loss = []\n",
        "  subject_y_loss = []\n",
        "  for j in range(len(predictions[i])): #144\n",
        "    subject_trial_x_loss = abs(predictions[i][j][0] - y_true[i][j][0])\n",
        "    subject_trial_y_loss = abs(predictions[i][j][1] - y_true[i][j][1])\n",
        "    subject_x_loss.append(subject_trial_x_loss)\n",
        "    subject_y_loss.append(subject_trial_y_loss)\n",
        "    # subject_x_loss.append(subject_trial_x_loss if subject_trial_x_loss < 0.12 else float('nan'))\n",
        "    # subject_y_loss.append(subject_trial_y_loss if subject_trial_y_loss < 0.12 else float('nan'))\n",
        "  x_losses.append(subject_x_loss)\n",
        "  y_losses.append(subject_y_loss)\n",
        "  batch_losses.append(loss)\n",
        "\n",
        "batch_losses = np.array(batch_losses)\n",
        "x_losses = np.array(x_losses)\n",
        "y_losses = np.array(y_losses)"
      ],
      "metadata": {
        "id": "HGuTNVJdVa0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_y_losses = np.sqrt(np.add(np.square(y_losses.ravel()), np.square(x_losses.ravel())))"
      ],
      "metadata": {
        "id": "3xy2_Jfdi-F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_losses = x_losses.ravel()\n",
        "y_losses = y_losses.ravel()"
      ],
      "metadata": {
        "id": "fb-Nx0U2lB8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "n, bins, patches = plt.hist(y_losses, bins=np.arange(0,0.2, 0.001), edgecolor='white')\n",
        "plt.title('Histogram of Model Error')\n",
        "plt.xlabel('Avg. Error - Proportion of Screen Diagonal')\n",
        "plt.ylabel('# subjects')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vlmVH1aJjffs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_losses_sorted = []\n",
        "y_losses_sorted = []\n",
        "y_true_subject_sorted = []\n",
        "for y_true_subject, *loss_arrays in zip(y_true, *[x_losses, y_losses]):\n",
        "  sorted_indices = sorted(range(len(y_true_subject)), key=lambda i: (y_true_subject[i][0], y_true_subject[i][1]))\n",
        "  y_true_subject_sorted.append([y_true_subject[i] for i in sorted_indices])\n",
        "  x_losses_sorted.append([loss_arrays[0][i] for i in sorted_indices])\n",
        "  y_losses_sorted.append([loss_arrays[1][i] for i in sorted_indices])"
      ],
      "metadata": {
        "id": "-MGvPsm-wXYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_losses_avg = np.nanmean(x_losses_sorted, axis=0)\n",
        "y_losses_avg = np.nanmean(y_losses_sorted, axis=0)"
      ],
      "metadata": {
        "id": "9a3NZC7Bkphc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_losses_avg = x_losses_avg.reshape(9, 16)\n",
        "y_losses_avg = y_losses_avg.reshape(9, 16)"
      ],
      "metadata": {
        "id": "v62LQG8ImqfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(x_losses_avg, vmin=0, vmax=0.12, cmap=\"RdYlBu_r\")\n",
        "\n",
        "ax.set_xticks(np.arange(len(cols)), labels=cols)\n",
        "ax.set_yticks(np.arange(len(rows)), labels=rows)\n",
        "\n",
        "\n",
        "# Loop over data dimensions and create text annotations.\n",
        "for i in range(len(rows)):\n",
        "    for j in range(len(cols)):\n",
        "        text = ax.text(j, i, np.round(x_losses_avg[i, j], decimals=2),\n",
        "                       ha=\"center\", va=\"center\", color=\"k\")\n",
        "\n",
        "ax.set_title(\"Horizontal Loss\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BFXF9S2xJL5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(y_losses_avg, vmin=0, vmax=0.12, cmap=\"RdYlBu_r\")\n",
        "\n",
        "ax.set_xticks(np.arange(len(cols)), labels=cols)\n",
        "ax.set_yticks(np.arange(len(rows)), labels=rows)\n",
        "\n",
        "\n",
        "# Loop over data dimensions and create text annotations.\n",
        "for i in range(len(rows)):\n",
        "    for j in range(len(cols)):\n",
        "        text = ax.text(j, i, np.round(y_losses_avg[i, j], decimals=2),\n",
        "                       ha=\"center\", va=\"center\", color=\"k\")\n",
        "\n",
        "ax.set_title(\"Vertical Loss\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a6lcA34Sona7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_y_losses_avg = np.sqrt(np.add(np.square(y_losses_avg), np.square(x_losses_avg)))"
      ],
      "metadata": {
        "id": "JoukZgVtp-QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(x_y_losses_avg, vmin=0, vmax=0.12, cmap=\"RdYlBu_r\")\n",
        "\n",
        "ax.set_xticks(np.arange(len(cols)), labels=cols)\n",
        "ax.set_yticks(np.arange(len(rows)), labels=rows)\n",
        "\n",
        "\n",
        "# Loop over data dimensions and create text annotations.\n",
        "for i in range(len(rows)):\n",
        "    for j in range(len(cols)):\n",
        "        text = ax.text(j, i, np.round(x_y_losses_avg[i, j], decimals=2),\n",
        "                       ha=\"center\", va=\"center\", color=\"k\")\n",
        "\n",
        "ax.set_title(\"Horizontal + Vertical Loss\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NUIawdEMf_k6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "G9LAJHmSmF84",
        "er9v9bxBcHc0",
        "wKeHGiFxtvo0",
        "kFgWOhWTt4iD",
        "YgNRPZIhncRM",
        "t19yxxx_Ts8H",
        "rzxl5IX0ycoR",
        "HIxNESdIRyue",
        "g9k1pHkzWXtE",
        "RlSR_8-4N1WC",
        "G0gob8OHu6q6"
      ],
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}